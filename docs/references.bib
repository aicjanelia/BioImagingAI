@article{stringer2021,
	title = {Cellpose: a generalist algorithm for cellular segmentation},
	volume = {18},
	issn = {1548-7105},
	shorttitle = {Cellpose},
	url = {https://www.nature.com/articles/s41592-020-01018-x},
	doi = {10.1038/s41592-020-01018-x},
	language = {en},
	number = {1},
	urldate = {2024-06-03},
	journal = {Nature Methods},
	author = {Stringer, Carsen and Wang, Tim and Michaelos, Michalis and Pachitariu, Marius},
	month = jan,
	year = {2021},
  publisher = {Nature Publishing Group},
	pages = {100--106}
  }

@article{von_chamier2021,
	title = {Democratising deep learning for microscopy with {ZeroCostDL4Mic}},
	volume = {12},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-22518-0},
	doi = {10.1038/s41467-021-22518-0},
	language = {en},
	number = {1},
	urldate = {2022-06-24},
	journal = {Nature Communications},
	author = {von Chamier, Lucas and Laine, Romain F. and Jukkala, Johanna and Spahn, Christoph and Krentzel, Daniel and Nehme, Elias and Lerche, Martina and Hernández-Pérez, Sara and Mattila, Pieta K. and Karinou, Eleni and Holden, Séamus and Solak, Ahmet Can and Krull, Alexander and Buchholz, Tim-Oliver and Jones, Martin L. and Royer, Loïc A. and Leterrier, Christophe and Shechtman, Yoav and Jug, Florian and Heilemann, Mike and Jacquemet, Guillaume and Henriques, Ricardo},
	month = apr,
	year = {2021},
  ublisher = {Nature Publishing Group},
	pages = {2276},
}

@article{guo_deep_2025,
	title = {Deep learning-based aberration compensation improves contrast and resolution in fluorescence microscopy},
	volume = {16},
	issn = {2041-1723},
	url = {https://doi.org/10.1038/s41467-024-55267-x},
	doi = {10.1038/s41467-024-55267-x},
	abstract = {Optical aberrations hinder fluorescence microscopy of thick samples, reducing image signal, contrast, and resolution. Here we introduce a deep learning-based strategy for aberration compensation, improving image quality without slowing image acquisition, applying additional dose, or introducing more optics. Our method (i) introduces synthetic aberrations to images acquired on the shallow side of image stacks, making them resemble those acquired deeper into the volume and (ii) trains neural networks to reverse the effect of these aberrations. We use simulations and experiments to show that applying the trained ‘de-aberration’ networks outperforms alternative methods, providing restoration on par with adaptive optics techniques; and subsequently apply the networks to diverse datasets captured with confocal, light-sheet, multi-photon, and super-resolution microscopy. In all cases, the improved quality of the restored data facilitates qualitative image inspection and improves downstream image quantitation, including orientational analysis of blood vessels in mouse tissue and improved membrane and nuclear segmentation in C. elegans embryos.},
	number = {1},
	journal = {Nature Communications},
	author = {Guo, Min and Wu, Yicong and Hobson, Chad M. and Su, Yijun and Qian, Shuhao and Krueger, Eric and Christensen, Ryan and Kroeschell, Grant and Bui, Johnny and Chaw, Matthew and Zhang, Lixia and Liu, Jiamin and Hou, Xuekai and Han, Xiaofei and Lu, Zhiye and Ma, Xuefei and Zhovmer, Alexander and Combs, Christian and Moyle, Mark and Yemini, Eviatar and Liu, Huafeng and Liu, Zhiyi and Benedetto, Alexandre and La Riviere, Patrick and Colón-Ramos, Daniel and Shroff, Hari},
	month = jan,
	year = {2025},
	pages = {313},
}

@article{Wu2022,
	author={Wu, Yicong and Shroff, Hari},
	title={Multiscale fluorescence imaging of living samples},
	journal={Histochemistry and Cell Biology},
	year={2022},
	month={Oct},
	day={01},
	volume={158},
	number={4},
	pages={301-323},
	abstract={Fluorescence microscopy is a highly effective tool for interrogating biological structure and function, particularly when imaging across multiple spatiotemporal scales. Here we survey recent innovations and applications in the relatively understudied area of multiscale fluorescence imaging of living samples. We discuss fundamental challenges in live multiscale imaging and describe successful examples that highlight the power of this approach. We attempt to synthesize general strategies from these test cases, aiming to help accelerate progress in this exciting area.},
	issn={1432-119X},
	doi={10.1007/s00418-022-02147-4},
	url={https://doi.org/10.1007/s00418-022-02147-4}
	}

@article{Schermelleh2010,
    author = {Schermelleh, Lothar and Heintzmann, Rainer and Leonhardt, Heinrich},
    title = {A guide to super-resolution fluorescence microscopy},
    journal = {Journal of Cell Biology},
    volume = {190},
    number = {2},
    pages = {165-175},
    year = {2010},
    month = {07},
    abstract = {For centuries, cell biology has been based on light microscopy and at the same time been limited by its optical resolution. However, several new technologies have been developed recently that bypass this limit. These new super-resolution technologies are either based on tailored illumination, nonlinear fluorophore responses, or the precise localization of single molecules. Overall, these new approaches have created unprecedented new possibilities to investigate the structure and function of cells.},
    issn = {0021-9525},
    doi = {10.1083/jcb.201002018},
    url = {https://doi.org/10.1083/jcb.201002018},
    eprint = {https://rupress.org/jcb/article-pdf/190/2/165/1568325/jcb\_201002018.pdf},
}

@article{Archit2025,
	author={Archit, Anwai 	and Freckmann, Luca	and Nair, Sushmita	and Khalid, Nabeel	and Hilt, Paul	and Rajashekar, Vikas	and Freitag, Marei	and Teuber, Carolin	and Spitzner, Melanie	and Tapia Contreras, Constanza	and Buckley, Genevieve	and von Haaren, Sebastian	and Gupta, Sagnik	and Grade, Marian	and Wirth, Matthias and Schneider, G{\"u}nter	and Dengel, Andreas	and Ahmed, Sheraz	and Pape, Constantin},
	title={Segment Anything for Microscopy},
	journal={Nature Methods},
	year={2025},
	month={Mar},
	day={01},
	volume={22},
	number={3},
	pages={579-591},
	abstract={Accurate segmentation of objects in microscopy images remains a bottleneck for many researchers despite the number of tools developed for this purpose. Here, we present Segment Anything for Microscopy ($\mu$SAM), a tool for segmentation and tracking in multidimensional microscopy data. It is based on Segment Anything, a vision foundation model for image segmentation. We extend it by fine-tuning generalist models for light and electron microscopy that clearly improve segmentation quality for a wide range of imaging conditions. We also implement interactive and automatic segmentation in a napari plugin that can speed up diverse segmentation tasks and provides a unified solution for microscopy annotation across different microscopy modalities. Our work constitutes the application of vision foundation models in microscopy, laying the groundwork for solving image analysis tasks in this domain with a small set of powerful deep learning models.},
	issn={1548-7105},
	doi={10.1038/s41592-024-02580-4},
	url={https://doi.org/10.1038/s41592-024-02580-4}
}

@Article{Sahl2017,
	author={Sahl, Steffen J.	and Hell, Stefan W.	and Jakobs, Stefan},
	title={Fluorescence nanoscopy in cell biology},
	journal={Nature Reviews Molecular Cell Biology},
	year={2017},
	month={Nov},
	day={01},
	volume={18},
	number={11},
	pages={685-701},
	abstract={Fluorescence nanoscopy (also known as super-resolution microscopy) methods have expanded optical imaging to reach the nanometre resolution range, typically 20--50 nm and even down to the 1 nm level.Diffraction-unlimited nanoscopy methods, which neutralize the resolution-limiting role of diffraction, separate fluorophores by transiently transferring them between (at least) two discernible states, typically an 'on' and an 'off' state of fluorescence.The counting of molecules in nanoscale settings such as within organelles is a crucially important development, along with labelling strategies to reliably pinpoint the locations and spatial proximities of all the molecules investigated in an imaging experiment.Dynamic nanoscopy and extensions of nanoscopy imaging to tissue and in vivo contexts are further frontiers.Examples taken from mitochondrial biology and neurobiology illustrate the capabilities and discovery potential of nanoscale molecule-specific imaging with focused light.},
	issn={1471-0080},
	doi={10.1038/nrm.2017.71},
	url={https://doi.org/10.1038/nrm.2017.71}
}

@article{Schermelleh2019,
	author={Schermelleh, Lothar 	and Ferrand, Alexia	and Huser, Thomas	and Eggeling, Christian	and Sauer, Markus	and Biehlmaier, Oliver	and Drummen, Gregor P. C.},
	title={Super-resolution microscopy demystified},
	journal={Nature Cell Biology},
	year={2019},
	month={Jan},
	day={01},
	volume={21},
	number={1},
	pages={72-84},
	abstract={Super-resolution microscopy (SRM) bypasses the diffraction limit, a physical barrier that restricts the optical resolution to roughly 250 nm and was previously thought to be impenetrable. SRM techniques allow the visualization of subcellular organization with unprecedented detail, but also confront biologists with the challenge of selecting the best-suited approach for their particular research question. Here, we provide guidance on how to use SRM techniques advantageously for investigating cellular structures and dynamics to promote new discoveries.},
	issn={1476-4679},
	doi={10.1038/s41556-018-0251-8},
	url={https://doi.org/10.1038/s41556-018-0251-8}
}

@article{Ji2017,
	author={Ji, Na},
	title={Adaptive optical fluorescence microscopy},
	journal={Nature Methods},
	year={2017},
	month={Apr},
	day={01},
	volume={14},
	number={4},
	pages={374-380},
	abstract={This Perspective introduces the development and use of adaptive optics in correcting aberrations in deep optical imaging applications.},
	issn={1548-7105},
	doi={10.1038/nmeth.4218},
	url={https://doi.org/10.1038/nmeth.4218}
}

@article{Hampson2021,
	author={Hampson, Karen M.	and Turcotte, Rapha{\"e}l	and Miller, Donald T.	and Kurokawa, Kazuhiro	and Males, Jared R.	and Ji, Na	and Booth, Martin J.},
	title={Adaptive optics for high-resolution imaging},
	journal={Nature Reviews Methods Primers},
	year={2021},
	month={Oct},
	day={14},
	volume={1},
	number={1},
	pages={68},
	abstract={Adaptive optics (AO) is a technique that corrects for optical aberrations. It was originally proposed to correct for the blurring effect of atmospheric turbulence on images in ground-based telescopes and was instrumental in the work that resulted in the Nobel prize-winning discovery of a supermassive compact object at the centre of our galaxy. When AO is used to correct for the eye's imperfect optics, retinal changes at the cellular level can be detected, allowing us to study the operation of the visual system and to assess ocular health in the microscopic domain. By correcting for sample-induced blur in microscopy, AO has pushed the boundaries of imaging in thick tissue specimens, such as when observing neuronal processes in the brain. In this primer, we focus on the application of AO for high-resolution imaging in astronomy, vision science and microscopy. We begin with an overview of the general principles of AO and its main components, which include methods to measure the aberrations, devices for aberration correction, and how these components are linked in operation. We present results and applications from each field along with reproducibility considerations and limitations. Finally, we discuss future directions.},
	issn={2662-8449},
	doi={10.1038/s43586-021-00066-7},
	url={https://doi.org/10.1038/s43586-021-00066-7}
}

@article{Shroff2024,
	author={Shroff, Hari	and Testa, Ilaria	and Jug, Florian	and Manley, Suliana},
	title={Live-cell imaging powered by computation},
	journal={Nature Reviews Molecular Cell Biology},
	year={2024},
	month={Jun},
	day={01},
	volume={25},
	number={6},
	pages={443-463},
	abstract={The proliferation of microscopy methods for live-cell imaging offers many new possibilities for users but can also be challenging to navigate. The prevailing challenge in live-cell fluorescence microscopy is capturing intra-cellular dynamics while preserving cell viability. Computational methods can help to address this challenge and are now shifting the boundaries of what is possible to capture in living systems. In this Review, we discuss these computational methods focusing on artificial intelligence-based approaches that can be layered on top of commonly used existing microscopies as well as hybrid methods that integrate computation and microscope hardware. We specifically discuss how computational approaches can improve the signal-to-noise ratio, spatial resolution, temporal resolution and multi-colour capacity of live-cell imaging.},
	issn={1471-0080},
	doi={10.1038/s41580-024-00702-6},
	url={https://doi.org/10.1038/s41580-024-00702-6}
}

@article{Venkatesh2015,
    author = {Venkatesh, Manasij and Mohan, Kavya and Seelamantula, Chandra Sekhar},
    title = {Directional bilateral filters for smoothing fluorescence microscopy images},
    journal = {AIP Advances},
    volume = {5},
    number = {8},
    pages = {084805},
    year = {2015},
    month = {08},
    abstract = { Images obtained through fluorescence microscopy at low numerical aperture (NA) are noisy and have poor resolution. Images of specimens such as F-actin filaments obtained using confocal or widefield fluorescence microscopes contain directional information and it is important that an image smoothing or filtering technique preserve the directionality. F-actin filaments are widely studied in pathology because the abnormalities in actin dynamics play a key role in diagnosis of cancer, cardiac diseases, vascular diseases, myofibrillar myopathies, neurological disorders, etc. We develop the directional bilateral filter as a means of filtering out the noise in the image without significantly altering the directionality of the F-actin filaments. The bilateral filter is anisotropic to start with, but we add an additional degree of anisotropy by employing an oriented domain kernel for smoothing. The orientation is locally adapted using a structure tensor and the parameters of the bilateral filter are optimized for within the framework of statistical risk minimization. We show that the directional bilateral filter has better denoising performance than the traditional Gaussian bilateral filter and other denoising techniques such as SURE-LET, non-local means, and guided image filtering at various noise levels in terms of peak signal-to-noise ratio (PSNR). We also show quantitative improvements in low NA images of F-actin filaments. },
    issn = {2158-3226},
    doi = {10.1063/1.4930029},
    url = {https://doi.org/10.1063/1.4930029},
    eprint = {https://pubs.aip.org/aip/adv/article-pdf/doi/10.1063/1.4930029/12895317/084805\_1\_online.pdf},
}

@article{Danielyan2014,
	title = {Denoising of two-photon fluorescence images with Block-Matching 3D filtering},
	journal = {Methods},
	volume = {68},
	number = {2},
	pages = {308-316},
	year = {2014},
	note = {Tools and Methods for Cellular Localization and Measurements},
	issn = {1046-2023},
	doi = {https://doi.org/10.1016/j.ymeth.2014.03.010},
	url = {https://www.sciencedirect.com/science/article/pii/S1046202314001030},
	author = {Aram Danielyan and Yu-Wei Wu and Pei-Yu Shih and Yulia Dembitskaya and Alexey Semyanov},
	keywords = {Noise modeling, Denoising, Two-photon fluorescent imaging, Ca dynamics},
	abstract = {Two-photon florescence imaging is widely used to perform morphological analysis of subcellular structures such as neuronal dendrites and spines, astrocytic processes etc. This method is also indispensable for functional analysis of cellular activity such as Ca2+ dynamics. Although spatial resolution of laser scanning two-photon system is greater than that of confocal or wide field microscope, it is still diffraction limited. In practice, the resolution of the system is more affected by its signal-to-noise ratio (SNR) than the diffraction limit. Thus, various approaches aiming to increase the SNR in two-photon imaging are desirable and can potentially save on building costly super-resolution imaging system. Here we analyze the statistics of noise in the two-photon florescence images of hippocampal astrocytes expressing genetically encoded Ca2+ sensor GCaMP2 and show that it can be reasonably well approximated using the same models which are used for describing noise in images acquired with digital cameras. This allows to use denoising methods available for wide field imaging on two-photon images. Particularly we demonstrate that the Block-Matching 3D (BM3D) filter can significantly improve the quality of two-photon fluorescence images so small details such as astrocytic processes can be easier identified. Moreover, denoising of the images with BM3D yields less noisy Ca2+ signals in astrocytes when denoising of the images with Gaussian filter.}
}

@INPROCEEDINGS{Zhang2019,
  author={Zhang, Yide and Zhu, Yinhao and Nichols, Evan and Wang, Qingfei and Zhang, Siyuan and Smith, Cody and Howard, Scott},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={A Poisson-Gaussian Denoising Dataset With Real Fluorescence Microscopy Images}, 
  year={2019},
  volume={},
  number={},
  pages={11702-11710},
  keywords={Datasets and Evaluation;Medical;Biological and Cell Microscopy},
  doi={10.1109/CVPR.2019.01198}
}

@INPROCEEDINGS{Li2017,
  author={Li, Jizhou and Luisier, Florian and Blu, Thierry},
  booktitle={2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017)}, 
  title={Pure-let deconvolution of 3D fluorescence microscopy images}, 
  year={2017},
  volume={},
  number={},
  pages={723-727},
  keywords={Microscopy;Three-dimensional displays;Deconvolution;Noise measurement;Bars;Noise level;Wavelet transforms;3D deconvolution;fluorescence microscopy;Poisson noise;unbiased risk estimate},
  doi={10.1109/ISBI.2017.7950621}
}

@ARTICLE{Makitalo2013,
  author={Makitalo, Markku and Foi, Alessandro},
  journal={IEEE Transactions on Image Processing}, 
  title={Optimal Inversion of the Generalized Anscombe Transformation for Poisson-Gaussian Noise}, 
  year={2013},
  volume={22},
  number={1},
  pages={91-103},
  keywords={Noise reduction;Approximation methods;Gaussian noise;Standards;Accuracy;Photonics;Denoising;photon-limited imaging;Poisson-Gaussian noise;variance stabilization},
  doi={10.1109/TIP.2012.2202675}
}

@article{Luisier2010,
	title = {Fast interscale wavelet denoising of Poisson-corrupted images},
	journal = {Signal Processing},
	volume = {90},
	number = {2},
	pages = {415-427},
	year = {2010},
	issn = {0165-1684},
	doi = {https://doi.org/10.1016/j.sigpro.2009.07.009},
	url = {https://www.sciencedirect.com/science/article/pii/S0165168409003016},
	author = {Florian Luisier and Cédric Vonesch and Thierry Blu and Michael Unser},
	keywords = {Poisson, Interscale, Denoising, Wavelets, Risk estimation, Linear expansion of thresholds, Fluorescence microscopy},
	abstract = {We present a fast algorithm for image restoration in the presence of Poisson noise. Our approach is based on (1) the minimization of an unbiased estimate of the MSE for Poisson noise, (2) a linear parametrization of the denoising process and (3) the preservation of Poisson statistics across scales within the Haar DWT. The minimization of the MSE estimate is performed independently in each wavelet subband, but this is equivalent to a global image-domain MSE minimization, thanks to the orthogonality of Haar wavelets. This is an important difference with standard Poisson noise-removal methods, in particular those that rely on a non-linear preprocessing of the data to stabilize the variance. Our non-redundant interscale wavelet thresholding outperforms standard variance-stabilizing schemes, even when the latter are applied in a translation-invariant setting (cycle-spinning). It also achieves a quality similar to a state-of-the-art multiscale method that was specially developed for Poisson data. Considering that the computational complexity of our method is orders of magnitude lower, it is a very competitive alternative. The proposed approach is particularly promising in the context of low signal intensities and/or large data sets. This is illustrated experimentally with the denoising of low-count fluorescence micrographs of a biological sample.}
}

@article{Van_der_Walt2014,
  title     = "scikit-image: image processing in Python",
  author    = "van der Walt, St{\'e}fan and Sch{\"o}nberger, Johannes L and
               Nunez-Iglesias, Juan and Boulogne, Fran{\c c}ois and Warner,
               Joshua D and Yager, Neil and Gouillart, Emmanuelle and Yu, Tony
               and {scikit-image contributors}",
  abstract  = "scikit-image is an image processing library that implements
               algorithms and utilities for use in research, education and
               industry applications. It is released under the liberal Modified
               BSD open source license, provides a well-documented API in the
               Python programming language, and is developed by an active,
               international team of collaborators. In this paper we highlight
               the advantages of open source to achieve the goals of the
               scikit-image library, and we showcase several real-world image
               processing applications that use scikit-image. More information
               can be found on the project homepage, http://scikit-image.org.",
  journal   = "PeerJ",
  publisher = "PeerJ",
  volume    =  2,
  pages     = "e453",
  month     =  jun,
  year      =  2014,
  keywords  = "Education; Image processing; Open source; Python; Reproducible
               research; Scientific programming; Visualization",
  language  = "en"
}

@book{Wiener1949,
    author = {Wiener, Norbert},
    title = {Extrapolation, Interpolation, and Smoothing of Stationary Time Series: With Engineering Applications},
    publisher = {The MIT Press},
    year = {1949},
    month = {08},
    abstract = {A book thatbecame the basis for modern communication theory, by a scientist considered one of the founders of the field of artifical intelligence.Some predict that Norbert Wiener will be remembered for his Extrapolation long after Cybernetics is forgotten. Indeed, few computer science students would know today what cybernetics is all about, while every communication student knows what Wiener's filter is. The original work was circulated as a classified memorandum in 1942, because it was connected with sensitive wartime efforts to improve radar communication. This book became the basis for modern communication theory, by a scientist considered one of the founders of the field of artifical intelligence. Combining ideas from statistics and time-series analysis, Wiener used Gauss's method of shaping the characteristic of a detector to allow for the maximal recognition of signals in the presence of noise. This method came to be known as the "Wiener filter."},
    isbn = {9780262257190},
    doi = {10.7551/mitpress/2946.001.0001},
    url = {https://doi.org/10.7551/mitpress/2946.001.0001},
    eprint = {https://direct.mit.edu/book-pdf/2313079/book\_9780262257190.pdf},
}

@article{Tikhonov1963,
  added-at = {2008-10-07T16:03:39.000+0200},
  author = {Tikhonov, A. N.},
  journal = {Soviet Math. Dokl.},
  pages = {1035--1038},
  timestamp = {2008-10-07T16:03:39.000+0200},
  title = {Solution of incorrectly formulated problems and the regularization method},
  volume = 4,
  year = 1963
}

@article{Miller1970,
	author = {Miller, Keith},
	title = {Least Squares Methods for Ill-Posed Problems with a Prescribed Bound},
	journal = {SIAM Journal on Mathematical Analysis},
	volume = {1},
	number = {1},
	pages = {52-74},
	year = {1970},
	doi = {10.1137/0501006},
	URL = {https://doi.org/10.1137/0501006},
	eprint = {https://doi.org/10.1137/0501006}
}

@article{Beck2009,
	author = {Beck, Amir and Teboulle, Marc},
	title = {A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems},
	journal = {SIAM Journal on Imaging Sciences},
	volume = {2},
	number = {1},
	pages = {183-202},
	year = {2009},
	doi = {10.1137/080716542},
	URL = {https://doi.org/10.1137/080716542},
	eprint = {https://doi.org/10.1137/080716542},
    abstract = { Abstract. We consider the class of iterative shrinkage-thresholding algorithms (ISTA) for solving linear inverse problems arising in signal/image processing. This class of methods, which can be viewed as an extension of the classical gradient algorithm, is attractive due to its simplicity and thus is adequate for solving large-scale problems even with dense matrix data. However, such methods are also known to converge quite slowly. In this paper we present a new fast iterative shrinkage-thresholding algorithm (FISTA) which preserves the computational simplicity of ISTA but with a global rate of convergence which is proven to be significantly better, both theoretically and practically. Initial promising numerical results for wavelet-based image deblurring demonstrate the capabilities of FISTA which is shown to be faster than ISTA by several orders of magnitude. }
}

@ARTICLE{Lucy1974,
       author = {{Lucy}, L.~B.},
        title = "{An iterative technique for the rectification of observed distributions}",
      journal = {\aj},
         year = 1974,
        month = jun,
       volume = {79},
        pages = {745},
          doi = {10.1086/111605},
       adsurl = {https://ui.adsabs.harvard.edu/abs/1974AJ.....79..745L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{Richardson1972,
	author = {William Hadley Richardson},
	journal = {J. Opt. Soc. Am.},
	keywords = {Crosstalk; Deconvolution; Image processing; Image restoration; Imaging techniques; Point spread function},
	number = {1},
	pages = {55--59},
	publisher = {Optica Publishing Group},
	title = {Bayesian-Based Iterative Method of Image Restoration$\ast$},
	volume = {62},
	month = {Jan},
	year = {1972},
	url = {https://opg.optica.org/abstract.cfm?URI=josa-62-1-55},
	doi = {10.1364/JOSA.62.000055},
	abstract = {An iterative method of restoring degraded images was developed by treating images, point spread functions, and degraded images as probability-frequency functions and by applying Bayes's theorem. The method functions effectively in the presence of noise and is adaptable to computer operation.},
}

@article{Sarder2006,
  author={Sarder, P. and Nehorai, A.},
  journal={IEEE Signal Processing Magazine}, 
  title={Deconvolution methods for 3-D fluorescence microscopy images}, 
  year={2006},
  volume={23},
  number={3},
  pages={32-45},
  keywords={Deconvolution;Fluorescence;Microscopy;Optical distortion;Adaptive optics;Biomedical optical imaging;Optical sensors;Optical noise;Optical computing;Optical imaging},
  doi={10.1109/MSP.2006.1628876}}

@incollection{Goodwin2014,
	title = {Chapter 10 - Quantitative deconvolution microscopy},
	editor = {Jennifer C. Waters and Torsten Wittman},
	series = {Methods in Cell Biology},
	publisher = {Academic Press},
	volume = {123},
	pages = {177-192},
	year = {2014},
	booktitle = {Quantitative Imaging in Cell Biology},
	issn = {0091-679X},
	doi = {https://doi.org/10.1016/B978-0-12-420138-5.00010-0},
	url = {https://www.sciencedirect.com/science/article/pii/B9780124201385000100},
	author = {Paul C. Goodwin},
	keywords = {Deconvolution, Wide-field microscopy, Point-spread function, Fourier transforms, Deblurring, Image restoration, Live-cell imaging, Contrast},
	abstract = {The light microscope is an essential tool for the study of cells, organelles, biomolecules, and subcellular dynamics. A paradox exists in microscopy whereby the higher the needed lateral resolution, the more the image is degraded by out-of-focus information. This creates a significant need to generate axial contrast whenever high lateral resolution is required. One strategy for generating contrast is to measure or model the optical properties of the microscope and to use that model to algorithmically reverse some of the consequences of high-resolution imaging. Deconvolution microscopy implements model-based methods to enable the full diffraction-limited resolution of the microscope to be exploited even in complex and living specimens.}
}

@article{Guo2020,
	author={Guo, Min and Li, Yue and Su, Yijun and Lambert, Talley and Nogare, Damian Dalle and Moyle, Mark W. and Duncan, Leighton H. and Ikegami, Richard and Santella, Anthony
	and Rey-Suarez, Ivan and Green, Daniel and Beiriger, Anastasia and Chen, Jiji and Vishwasrao, Harshad and Ganesan, Sundar and Prince, Victoria and Waters, Jennifer C. and Annunziata, Christina M.
	and Hafner, Markus and Mohler, William A. and Chitnis, Ajay B. and Upadhyaya, Arpita and Usdin, Ted B. and Bao, Zhirong and Col{\'o}n-Ramos, Daniel and La Riviere, Patrick and Liu, Huafeng
	and Wu, Yicong and Shroff, Hari},
	title={Rapid image deconvolution and multiview fusion for optical microscopy},
	journal={Nature Biotechnology},
	year={2020},
	month={Nov},
	day={01},
	volume={38},
	number={11},
	pages={1337-1346},
	abstract={The contrast and resolution of images obtained with optical microscopes can be improved by deconvolution and computational fusion of multiple views of the same sample, but these methods are computationally expensive for large datasets. Here we describe theoretical and practical advances in algorithm and software design that result in image processing times that are tenfold to several thousand fold faster than with previous methods. First, we show that an `unmatched back projector' accelerates deconvolution relative to the classic Richardson--Lucy algorithm by at least tenfold. Second, three-dimensional image-based registration with a graphics processing unit enhances processing speed 10- to 100-fold over CPU processing. Third, deep learning can provide further acceleration, particularly for deconvolution with spatially varying point spread functions. We illustrate our methods from the subcellular to millimeter spatial scale on diverse samples, including single cells, embryos and cleared tissue. Finally, we show performance enhancement on recently developed microscopes that have improved spatial resolution, including dual-view cleared-tissue light-sheet microscopes and reflective lattice light-sheet microscopes.},
	issn={1546-1696},
	doi={10.1038/s41587-020-0560-x},
	url={https://doi.org/10.1038/s41587-020-0560-x}
}

@article{Schindelin2012,
	author={Schindelin, Johannes and Arganda-Carreras, Ignacio	and Frise, Erwin	and Kaynig, Verena	and Longair, Mark	and Pietzsch, Tobias	and Preibisch, Stephan
	and Rueden, Curtis 	and Saalfeld, Stephan 	and Schmid, Benjamin	and Tinevez, Jean-Yves	and White, Daniel James	and Hartenstein, Volker	and Eliceiri, Kevin
	and Tomancak, Pavel and Cardona, Albert},
	title={Fiji: an open-source platform for biological-image analysis},
	journal={Nature Methods},
	year={2012},
	month={Jul},
	day={01},
	volume={9},
	number={7},
	pages={676-682},
	abstract={Presented is an overview of the image-analysis software platform Fiji, a distribution of ImageJ that updates the underlying ImageJ architecture and adds modern software design elements to expand the capabilities of the platform and facilitate collaboration between biologists and computer scientists.},
	issn={1548-7105},
	doi={10.1038/nmeth.2019},
	url={https://doi.org/10.1038/nmeth.2019}
}

@article{Sage2017,
	title = {DeconvolutionLab2: An open-source software for deconvolution microscopy},
	journal = {Methods},
	volume = {115},
	pages = {28-41},
	year = {2017},
	note = {Image Processing for Biologists},
	issn = {1046-2023},
	doi = {https://doi.org/10.1016/j.ymeth.2016.12.015},
	url = {https://www.sciencedirect.com/science/article/pii/S1046202316305096},
	author = {Daniel Sage and Lauréne Donati and Ferréol Soulez and Denis Fortun and Guillaume Schmit and Arne Seitz and Romain Guiet and Cédric Vonesch and Michael Unser},
	keywords = {Deconvolution microscopy, Open-source software, Standard algorithms, Textbook approach, Reference datasets},
	abstract = {Images in fluorescence microscopy are inherently blurred due to the limit of diffraction of light. The purpose of deconvolution microscopy is to compensate numerically for this degradation. Deconvolution is widely used to restore fine details of 3D biological samples. Unfortunately, dealing with deconvolution tools is not straightforward. Among others, end users have to select the appropriate algorithm, calibration and parametrization, while potentially facing demanding computational tasks. To make deconvolution more accessible, we have developed a practical platform for deconvolution microscopy called DeconvolutionLab. Freely distributed, DeconvolutionLab hosts standard algorithms for 3D microscopy deconvolution and drives them through a user-oriented interface. In this paper, we take advantage of the release of DeconvolutionLab2 to provide a complete description of the software package and its built-in deconvolution algorithms. We examine several standard algorithms used in deconvolution microscopy, notably: Regularized inverse filter, Tikhonov regularization, Landweber, Tikhonov–Miller, Richardson–Lucy, and fast iterative shrinkage-thresholding. We evaluate these methods over large 3D microscopy images using simulated datasets and real experimental images. We distinguish the algorithms in terms of image quality, performance, usability and computational requirements. Our presentation is completed with a discussion of recent trends in deconvolution, inspired by the results of the Grand Challenge on deconvolution microscopy that was recently organized.}
}

@article{Bazin2007,
	title = {Volumetric neuroimage analysis extensions for the MIPAV software package},
	journal = {Journal of Neuroscience Methods},
	volume = {165},
	number = {1},
	pages = {111-121},
	year = {2007},
	issn = {0165-0270},
	doi = {https://doi.org/10.1016/j.jneumeth.2007.05.024},
	url = {https://www.sciencedirect.com/science/article/pii/S0165027007002270},
	author = {Pierre-Louis Bazin and Jennifer L. Cuzzocreo and Michael A. Yassa and William Gandler and Matthew J. McAuliffe and Susan S. Bassett and Dzung L. Pham},
	keywords = {Segmentation, Magnetic resonance imaging, Talairach atlas},
	abstract = {We describe a new collection of publicly available software tools for performing quantitative neuroimage analysis. The tools perform semi-automatic brain extraction, tissue classification, Talairach alignment, and atlas-based measurements within a user-friendly graphical environment. They are implemented as plug-ins for MIPAV, a freely available medical image processing software package from the National Institutes of Health. Because the plug-ins and MIPAV are implemented in Java, both can be utilized on nearly any operating system platform. In addition to the software plug-ins, we have also released a digital version of the Talairach atlas that can be used to perform regional volumetric analyses. Several studies are conducted applying the new tools to simulated and real neuroimaging data sets.}
}

@article{Booth1861,
	ISSN = {1364503X},
	URL = {http://www.jstor.org/stable/25190627},
	abstract = {The imaging properties of optical microscopes are often compromised by aberrations that reduce image resolution and contrast. Adaptive optics technology has been employed in various systems to correct these aberrations and restore performance. This has required various departures from the traditional adaptive optics schemes that are used in astronomy. This review discusses the sources of aberrations, their effects and their correction with adaptive optics, particularly in confocal and two-photon microscopes. Different methods of wavefront sensing, indirect aberration measurement and aberration correction devices are discussed. Applications of adaptive optics in the related areas of optical data storage, optical tweezers and micro/nanofabrication are also reviewed.},
	author = {Martin J. Booth},
	journal = {Philosophical Transactions: Mathematical, Physical and Engineering Sciences},
	number = {1861},
	pages = {2829--2843},
	publisher = {The Royal Society},
	title = {Adaptive Optics in Microscopy},
	urldate = {2025-08-19},
	volume = {365},
	year = {2007}
}

@article{Hell2007,
	author = {Stefan W. Hell },
	title = {Far-Field Optical Nanoscopy},
	journal = {Science},
	volume = {316},
	number = {5828},
	pages = {1153-1158},
	year = {2007},
	doi = {10.1126/science.1137395},
	URL = {https://www.science.org/doi/abs/10.1126/science.1137395},
	eprint = {https://www.science.org/doi/pdf/10.1126/science.1137395},
	abstract = {In 1873, Ernst Abbe discovered what was to become a well-known paradigm: the inability of a lens-based optical microscope to discern details that are closer together than half of the wavelength of light. However, for its most popular imaging mode, fluorescence microscopy, the diffraction barrier is crumbling. Here, I discuss the physical concepts that have pushed fluorescence microscopy to the nanoscale, once the prerogative of electron and scanning probe microscopes. Initial applications indicate that emergent far-field optical nanoscopy will have a strong impact in the life sciences and in other areas benefiting from nanoscale visualization.}
}

@article{Vicidomini2018,
	author={Vicidomini, Giuseppe
	and Bianchini, Paolo
	and Diaspro, Alberto},
	title={STED super-resolved microscopy},
	journal={Nature Methods},
	year={2018},
	month={Mar},
	day={01},
	volume={15},
	number={3},
	pages={173-182},
	abstract={This Perspective reviews nanoscopy via stimulated emission depletion (STED), focusing on challenges for biologists and how technical advances are helping to meet these challenges.},
	issn={1548-7105},
	doi={10.1038/nmeth.4593},
	url={https://doi.org/10.1038/nmeth.4593}
}

@article{Wu2018,
	author={Wu, Yicong
	and Shroff, Hari},
	title={Faster, sharper, and deeper: structured illumination microscopy for biological imaging},
	journal={Nature Methods},
	year={2018},
	month={Dec},
	day={01},
	volume={15},
	number={12},
	pages={1011-1019},
	abstract={Structured illumination microscopy (SIM) allows rapid, super-resolution (SR) imaging in live specimens. We review recent technical advances in SR-SIM, with emphasis on imaging speed, resolution, and depth. Since its introduction decades ago, the technique has grown to offer myriad implementations, each with its own strengths and weaknesses. We discuss these, aiming to provide a practical guide for biologists and to highlight which approach is best suited to a given application.},
	issn={1548-7105},
	doi={10.1038/s41592-018-0211-z},
	url={https://doi.org/10.1038/s41592-018-0211-z}
}

@article{Chen2015,
	author = {Fei Chen  and Paul W. Tillberg  and Edward S. Boyden },
	title = {Expansion microscopy},
	journal = {Science},
	volume = {347},
	number = {6221},
	pages = {543-548},
	year = {2015},
	doi = {10.1126/science.1260088},
	URL = {https://www.science.org/doi/abs/10.1126/science.1260088},
	eprint = {https://www.science.org/doi/pdf/10.1126/science.1260088},
	abstract = {The resolution of a light microscope is limited. Physicists have long since worked out what these limits are and which parameters determine the spatial resolution. Many groups have nevertheless made numerous attempts to overcome these resolution limits. Rather than improving the power and quality of the microscope, Chen et al. instead expanded the biological specimens under study (see the Perspective by Dodt). They introduced a polymer gel into fixed cells and tissues and chemically induced swelling of the polymer by almost two orders of magnitude. They could then produce much higher-resolution images of their samples, which included the mouse hippocampus. Science, this issue p. 543; see also p. 474 A new approach to image fixed biological samples by expanding the specimen under study reveals mouse brain substructures. [Also see Perspective by Dodt] In optical microscopy, fine structural details are resolved by using refraction to magnify images of a specimen. We discovered that by synthesizing a swellable polymer network within a specimen, it can be physically expanded, resulting in physical magnification. By covalently anchoring specific labels located within the specimen directly to the polymer network, labels spaced closer than the optical diffraction limit can be isotropically separated and optically resolved, a process we call expansion microscopy (ExM). Thus, this process can be used to perform scalable superresolution microscopy with diffraction-limited microscopes. We demonstrate ExM with apparent ~70-nanometer lateral resolution in both cultured cells and brain tissue, performing three-color superresolution imaging of ~107 cubic micrometers of the mouse hippocampus with a conventional confocal microscope.}
}

@rticle{Wassie2019,
	author={Wassie, Asmamaw T.
	and Zhao, Yongxin
	and Boyden, Edward S.},
	title={Expansion microscopy: principles and uses in biological research},
	journal={Nature Methods},
	year={2019},
	month={Jan},
	day={01},
	volume={16},
	number={1},
	pages={33-41},
	abstract={Many biological investigations require 3D imaging of cells or tissues with nanoscale spatial resolution. We recently discovered that preserved biological specimens can be physically expanded in an isotropic fashion through a chemical process. Expansion microscopy (ExM) allows nanoscale imaging of biological specimens with conventional microscopes, decrowds biomolecules in support of signal amplification and multiplexed readout chemistries, and makes specimens transparent. We review the principles of how ExM works, advances in the technology made by our group and others, and its applications throughout biology and medicine.},
	issn={1548-7105},
	doi={10.1038/s41592-018-0219-4},
	url={https://doi.org/10.1038/s41592-018-0219-4}
}

@article{Valli2021,
	title = {Seeing beyond the limit: A guide to choosing the right super-resolution microscopy technique},
	journal = {Journal of Biological Chemistry},
	volume = {297},
	number = {1},
	pages = {100791},
	year = {2021},
	issn = {0021-9258},
	doi = {https://doi.org/10.1016/j.jbc.2021.100791},
	url = {https://www.sciencedirect.com/science/article/pii/S0021925821005846},
	author = {Jessica Valli and Adrian Garcia-Burgos and Liam M. Rooney and Beatriz {Vale de Melo e Oliveira} and Rory R. Duncan and Colin Rickman},
	keywords = {super resolution, microscopy, diffraction limit, fluorescence, localization, imaging, molecular imaging, molecular dynamics, protein–protein interactions},
	abstract = {Super-resolution microscopy has become an increasingly popular and robust tool across the life sciences to study minute cellular structures and processes. However, with the increasing number of available super-resolution techniques has come an increased complexity and burden of choice in planning imaging experiments. Choosing the right super-resolution technique to answer a given biological question is vital for understanding and interpreting biological relevance. This is an often-neglected and complex task that should take into account well-defined criteria (e.g., sample type, structure size, imaging requirements). Trade-offs in different imaging capabilities are inevitable; thus, many researchers still find it challenging to select the most suitable technique that will best answer their biological question. This review aims to provide an overview and clarify the concepts underlying the most commonly available super-resolution techniques as well as guide researchers through all aspects that should be considered before opting for a given technique.}
}

@article{Chen2024,
	author={Chen, Huanhuan
	and Yan, Guangjie
	and Wen, Meng-Hsuan
	and Brooks, Kameron N.
	and Zhang, Yuteng
	and Huang, Pei-San
	and Chen, Tai-Yen},
	title={Advancements and Practical Considerations for Biophysical Research: Navigating the Challenges and Future of Super-resolution Microscopy},
	journal={Chemical {\&} Biomedical Imaging},
	year={2024},
	month={May},
	day={27},
	publisher={American Chemical Society},
	volume={2},
	number={5},
	pages={331-344},
	doi={10.1021/cbmi.4c00019},
	url={https://doi.org/10.1021/cbmi.4c00019}
}

@article{Hagen2021,
    author = {Hagen, Guy M and Bendesky, Justin and Machado, Rosa and Nguyen, Tram-Anh and Kumar, Tanmay and Ventura, Jonathan},
    title = {Fluorescence microscopy datasets for training deep neural networks},
    journal = {GigaScience},
    volume = {10},
    number = {5},
    pages = {giab032},
    year = {2021},
    month = {05},
    abstract = {Fluorescence microscopy is an important technique in many areas of biological research. Two factors that limit the usefulness and performance of fluorescence microscopy are photobleaching of fluorescent probes during imaging and, when imaging live cells, phototoxicity caused by light exposure. Recently developed methods in machine learning are able to greatly improve the signal-to-noise ratio of acquired images. This allows researchers to record images with much shorter exposure times, which in turn minimizes photobleaching and phototoxicity by reducing the dose of light reaching the sample.To use deep learning methods, a large amount of data is needed to train the underlying convolutional neural network. One way to do this involves use of pairs of fluorescence microscopy images acquired with long and short exposure times. We provide high-quality datasets that can be used to train and evaluate deep learning methods under development.The availability of high-quality data is vital for training convolutional neural networks that are used in current machine learning approaches.},
    issn = {2047-217X},
    doi = {10.1093/gigascience/giab032},
    url = {https://doi.org/10.1093/gigascience/giab032},
    eprint = {https://academic.oup.com/gigascience/article-pdf/10/5/giab032/60688420/giab032.pdf},
}

@article{Weigert2018,
	author={Weigert, Martin 	and Schmidt, Uwe	and Boothe, Tobias	and M{\"u}ller, Andreas	and Dibrov, Alexandr	and Jain, Akanksha	and Wilhelm, Benjamin	and Schmidt, Deborah	and Broaddus, Coleman	and Culley, Si{\^a}n	and Rocha-Martins, Mauricio	and Segovia-Miranda, Fabi{\'a}n	and Norden, Caren	and Henriques, Ricardo and Zerial, Marino and Solimena, Michele	and Rink, Jochen and Tomancak, Pavel	and Royer, Loic	and Jug, Florian	and Myers, Eugene W.},
	title={Content-aware image restoration: pushing the limits of fluorescence microscopy},
	journal={Nature Methods},
	year={2018},
	month={Dec},
	day={01},
	volume={15},
	number={12},
	pages={1090-1097},
	abstract={Fluorescence microscopy is a key driver of discoveries in the life sciences, with observable phenomena being limited by the optics of the microscope, the chemistry of the fluorophores, and the maximum photon exposure tolerated by the sample. These limits necessitate trade-offs between imaging speed, spatial resolution, light exposure, and imaging depth. In this work we show how content-aware image restoration based on deep learning extends the range of biological phenomena observable by microscopy. We demonstrate on eight concrete examples how microscopy images can be restored even if 60-fold fewer photons are used during acquisition, how near isotropic resolution can be achieved with up to tenfold under-sampling along the axial direction, and how tubular and granular structures smaller than the diffraction limit can be resolved at 20-times-higher frame rates compared to state-of-the-art methods. All developed image restoration methods are freely available as open source software in Python, FIJI, and KNIME.},
	issn={1548-7105},
	doi={10.1038/s41592-018-0216-7},
	url={https://doi.org/10.1038/s41592-018-0216-7}
}

@article{Chen2021,
	author={Chen, Jiji	and Sasaki, Hideki	and Lai, Hoyin	and Su, Yijun	and Liu, Jiamin	and Wu, Yicong	and Zhovmer, Alexander	and Combs, Christian A.	and Rey-Suarez, Ivan	and Chang, Hung-Yu	and Huang, Chi Chou	and Li, Xuesong	and Guo, Min	and Nizambad, Srineil	and Upadhyaya, Arpita	and Lee, Shih-Jong J.	and Lucas, Luciano A. G.	and Shroff, Hari},
	title={Three-dimensional residual channel attention networks denoise and sharpen fluorescence microscopy image volumes},
	journal={Nature Methods},
	year={2021},
	month={Jun},
	day={01},
	volume={18},
	number={6},
	pages={678-687},
	abstract={We demonstrate residual channel attention networks (RCAN) for the restoration and enhancement of volumetric time-lapse (four-dimensional) fluorescence microscopy data. First we modify RCAN to handle image volumes, showing that our network enables denoising competitive with three other state-of-the-art neural networks. We use RCAN to restore noisy four-dimensional super-resolution data, enabling image capture of over tens of thousands of images (thousands of volumes) without apparent photobleaching. Second, using simulations we show that RCAN enables resolution enhancement equivalent to, or better than, other networks. Third, we exploit RCAN for denoising and resolution improvement in confocal microscopy, enabling {\textasciitilde}2.5-fold lateral resolution enhancement using stimulated emission depletion microscopy ground truth. Fourth, we develop methods to improve spatial resolution in structured illumination microscopy using expansion microscopy data as ground truth, achieving improvements of {\textasciitilde}1.9-fold laterally and {\textasciitilde}3.6-fold axially. Finally, we characterize the limits of denoising and resolution enhancement, suggesting practical benchmarks for evaluation and further enhancement of network performance.},
	issn={1548-7105},
	doi={10.1038/s41592-021-01155-x},
	url={https://doi.org/10.1038/s41592-021-01155-x}
}

@article{Qiao2021,
	author={Qiao, Chang	and Li, Di	and Guo, Yuting	and Liu, Chong	and Jiang, Tao	and Dai, Qionghai	and Li, Dong},
	title={Evaluation and development of deep neural networks for image super-resolution in optical microscopy},
	journal={Nature Methods},
	year={2021},
	month={Feb},
	day={01},
	volume={18},
	number={2},
	pages={194-202},
	abstract={Deep neural networks have enabled astonishing transformations from low-resolution (LR) to super-resolved images. However, whether, and under what imaging conditions, such deep-learning models outperform super-resolution (SR) microscopy is poorly explored. Here, using multimodality structured illumination microscopy (SIM), we first provide an extensive dataset of LR--SR image pairs and evaluate the deep-learning SR models in terms of structural complexity, signal-to-noise ratio and upscaling factor. Second, we devise the deep Fourier channel attention network (DFCAN), which leverages the frequency content difference across distinct features to learn precise hierarchical representations of high-frequency information about diverse biological structures. Third, we show that DFCAN's Fourier domain focalization enables robust reconstruction of SIM images under low signal-to-noise ratio conditions. We demonstrate that DFCAN achieves comparable image quality to SIM over a tenfold longer duration in multicolor live-cell imaging experiments, which reveal the detailed structures of mitochondrial cristae and nucleoids and the interaction dynamics of organelles and cytoskeleton.},
	issn={1548-7105},
	doi={10.1038/s41592-020-01048-5},
	url={https://doi.org/10.1038/s41592-020-01048-5}
}

@article{Hou2025,
	author = {Xuekai Hou and Yue Li and Chad M. Hobson and Hari Shroff and Min Guo and Huafeng Liu},
	journal = {Opt. Express},
	keywords = {Biomedical imaging; Deep learning; Fluorescence microscopy; Image enhancement; Image metrics; Optical aberration},
	number = {13},
	pages = {27317--27333},
	publisher = {Optica Publishing Group},
	title = {HD2Net: a deep learning framework for simultaneous denoising and deaberration in fluorescence microscopy},
	volume = {33},
	month = {Jun},
	year = {2025},
	url = {https://opg.optica.org/oe/abstract.cfm?URI=oe-33-13-27317},
	doi = {10.1364/OE.554927},
	abstract = {Fluorescence microscopy is essential for biological research, offering high-contrast imaging of microscopic structures. However, the quality of these images is often compromised by optical aberrations and noise, particularly in low signal-to-noise ratio (SNR) conditions. While adaptive optics (AO) can correct aberrations, it requires costly hardware and slows down imaging, whereas current denoising approaches boost the SNR but leave out the aberration compensation. To address these limitations, we introduce HD2Net, a deep-learning framework that enhances image quality by simultaneously denoising and suppressing the effect of aberrations without the need for additional hardware. Building on our previous work, HD2Net incorporates noise estimation and aberration removal modules, effectively restoring images degraded by noise and aberrations. Through comprehensive evaluation of synthetic phantoms and biological data, we demonstrate that HD2Net outperforms existing methods, significantly improving image resolution and contrast. This framework offers a promising solution for enhancing biological imaging, particularly in challenging aberrating and low-light conditions.},
}

@article{Zhang2017,
  author={Zhang, Kai and Zuo, Wangmeng and Chen, Yunjin and Meng, Deyu and Zhang, Lei},
  journal={IEEE Transactions on Image Processing}, 
  title={Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising}, 
  year={2017},
  volume={26},
  number={7},
  pages={3142-3155},
  keywords={Noise reduction;Image denoising;Training;Computational modeling;Noise level;Neural networks;Transform coding;Image denoising;convolutional neural networks;residual learning;batch normalization},
  doi={10.1109/TIP.2017.2662206}}

@article{Dabov2007,
  author={Dabov, Kostadin and Foi, Alessandro and Katkovnik, Vladimir and Egiazarian, Karen},
  journal={IEEE Transactions on Image Processing}, 
  title={Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering}, 
  year={2007},
  volume={16},
  number={8},
  pages={2080-2095},
  keywords={Image denoising;Collaboration;Filtering;Noise reduction;Signal processing algorithms;Signal processing;Energy resolution;Spatial resolution;Signal resolution;Discrete cosine transforms;Adaptive grouping;block matching;image denoising;sparsity;3-D transform shrinkage},
  doi={10.1109/TIP.2007.901238}}

@INPROCEEDINGS{Krull2019,
  author={Krull, Alexander and Buchholz, Tim-Oliver and Jug, Florian},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Noise2Void - Learning Denoising From Single Noisy Images}, 
  year={2019},
  volume={},
  number={},
  pages={2124-2132},
  keywords={Training;Photography;Deep learning;Noise reduction;Fluorescence;Pattern recognition;Noise measurement;Medical;Biological and Cell Microscopy;Deep Learning;Low-level Vision;Statistical Learning},
  doi={10.1109/CVPR.2019.00223}}


@InProceedings{Batson2019,
  title = 	 {{N}oise2{S}elf: Blind Denoising by Self-Supervision},
  author =       {Batson, Joshua and Royer, Loic},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {524--533},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/batson19a/batson19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/batson19a.html},
  abstract = 	 {We propose a general framework for denoising high-dimensional measurements which requires no prior on the signal, no estimate of the noise, and no clean training data. The only assumption is that the noise exhibits statistical independence across different dimensions of the measurement, while the true signal exhibits some correlation. For a broad class of functions (“$\mathcal{J}$-invariant”), it is then possible to estimate the performance of a denoiser from noisy data alone. This allows us to calibrate $\mathcal{J}$-invariant versions of any parameterised denoising algorithm, from the single hyperparameter of a median filter to the millions of weights of a deep neural network. We demonstrate this on natural image and microscopy data, where we exploit noise independence between pixels, and on single-cell gene expression data, where we exploit independence between detections of individual molecules. This framework generalizes recent work on training neural nets from noisy images and on cross-validation for matrix factorization.}
}


@InProceedings{Lehtinen2018,
  title = 	 {{N}oise2{N}oise: Learning Image Restoration without Clean Data},
  author =       {Lehtinen, Jaakko and Munkberg, Jacob and Hasselgren, Jon and Laine, Samuli and Karras, Tero and Aittala, Miika and Aila, Timo},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {2965--2974},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/lehtinen18a/lehtinen18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/lehtinen18a.html},
  abstract = 	 {We apply basic statistical reasoning to signal reconstruction by machine learning - learning to map corrupted observations to clean signals - with a simple and powerful conclusion: it is possible to learn to restore images by only looking at corrupted examples, at performance at and sometimes exceeding training using clean data, without explicit image priors or likelihood models of the corruption. In practice, we show that a single model learns photographic noise removal, denoising synthetic Monte Carlo images, and reconstruction of undersampled MRI scans - all corrupted by different processes - based on noisy data only.}
}

@article{Li2022,
	author={Li, Yue	and Su, Yijun	and Guo, Min	and Han, Xiaofei	and Liu, Jiamin	and Vishwasrao, Harshad D.	and Li, Xuesong	and Christensen, Ryan	and Sengupta, Titas	and Moyle, Mark W.	and Rey-Suarez, Ivan	and Chen, Jiji	and Upadhyaya, Arpita	and Usdin, Ted B.	and Col{\'o}n-Ramos, Daniel Alfonso	and Liu, Huafeng	and Wu, Yicong	and Shroff, Hari},
	title={Incorporating the image formation process into deep learning improves network performance},
	journal={Nature Methods},
	year={2022},
	month={Nov},
	day={01},
	volume={19},
	number={11},
	pages={1427-1437},
	abstract={We present Richardson--Lucy network (RLN), a fast and lightweight deep learning method for three-dimensional fluorescence microscopy deconvolution. RLN combines the traditional Richardson--Lucy iteration with a fully convolutional network structure, establishing a connection to the image formation process and thereby improving network performance. Containing only roughly 16,000 parameters, RLN enables four- to 50-fold faster processing than purely data-driven networks with many more parameters. By visual and quantitative analysis, we show that RLN provides better deconvolution, better generalizability and fewer artifacts than other networks, especially along the axial dimension. RLN outperforms classic Richardson--Lucy deconvolution on volumes contaminated with severe out of focus fluorescence or noise and provides four- to sixfold faster reconstructions of large, cleared-tissue datasets than classic multi-view pipelines. We demonstrate RLN's performance on cells, tissues and embryos imaged with widefield-, light-sheet-, confocal- and super-resolution microscopy.},
	issn={1548-7105},
	doi={10.1038/s41592-022-01652-7},
	url={https://doi.org/10.1038/s41592-022-01652-7}
}

@article{Yanny2022,
	author = {Kyrollos Yanny and Kristina Monakhova and Richard W. Shuai and Laura Waller},
	journal = {Optica},
	keywords = {Deep learning; Fourier transforms; Imaging systems; Inverse design; Neural networks; Three dimensional reconstruction},
	number = {1},
	pages = {96--99},
	publisher = {Optica Publishing Group},
	title = {Deep learning for fast spatially varying deconvolution},
	volume = {9},
	month = {Jan},
	year = {2022},
	url = {https://opg.optica.org/optica/abstract.cfm?URI=optica-9-1-96},
	doi = {10.1364/OPTICA.442438},
	abstract = {Deconvolution can be used to obtain sharp images or volumes from blurry or encoded measurements in imaging systems. Given knowledge of the system's point spread function (PSF) over the field of view, a reconstruction algorithm can be used to recover a clear image or volume. Most deconvolution algorithms assume shift-invariance; however, in realistic systems, the PSF varies laterally and axially across the field of view due to aberrations or design. Shift-varying models can be used, but are often slow and computationally intensive. In this work, we propose a deep-learning-based approach that leverages knowledge about the system's spatially varying PSFs for fast 2D and 3D reconstructions. Our approach, termed MultiWienerNet, uses multiple differentiable Wiener filters paired with a convolutional neural network to incorporate spatial variance. Trained using simulated data and tested on experimental data, our approach offers a 625{\textminus}1600{\texttimes} increase in speed compared to iterative methods with a spatially varying model, and outperforms existing deep-learning-based methods that assume shift invariance.},
}

@article{Saha2020,
	author = {Debayan Saha and Uwe Schmidt and Qinrong Zhang and Aurelien Barbotin and Qi Hu and Na Ji and Martin J. Booth and Martin Weigert and Eugene W. Myers},
	journal = {Opt. Express},
	keywords = {Deep learning; Deformable mirrors; Neural networks; Optical aberration; Spatial light modulators; Three dimensional microscopy},
	number = {20},
	pages = {29044--29053},
	publisher = {Optica Publishing Group},
	title = {Practical sensorless aberration estimation for 3D microscopy with deep learning},
	volume = {28},
	month = {Sep},
	year = {2020},
	url = {https://opg.optica.org/oe/abstract.cfm?URI=oe-28-20-29044},
	doi = {10.1364/OE.401933},
	abstract = {Estimation of optical aberrations from volumetric intensity images is a key step in sensorless adaptive optics for 3D microscopy. Recent approaches based on deep learning promise accurate results at fast processing speeds. However, collecting ground truth microscopy data for training the network is typically very difficult or even impossible thereby limiting this approach in practice. Here, we demonstrate that neural networks trained only on simulated data yield accurate predictions for real experimental images. We validate our approach on simulated and experimental datasets acquired with two different microscopy modalities and also compare the results to non-learned methods. Additionally, we study the predictability of individual aberrations with respect to their data requirements and find that the symmetry of the wavefront plays a crucial role. Finally, we make our implementation freely available as open source software in Python.},
}

@article{Kang2024,
   title={Coordinate-based neural representations for computational adaptive optics in widefield microscopy},
   volume={6},
   ISSN={2522-5839},
   url={http://dx.doi.org/10.1038/s42256-024-00853-3},
   DOI={10.1038/s42256-024-00853-3},
   number={6},
   journal={Nature Machine Intelligence},
   publisher={Springer Science and Business Media LLC},
   author={Kang, Iksung and Zhang, Qinrong and Yu, Stella X. and Ji, Na},
   year={2024},
   month=jun, 
   pages={714–725} 
}

@article {Kang2024.10.20.619284,
	author = {Kang, Iksung and Kim, Hyeonggeon and Natan, Ryan and Zhang, Qinrong and Yu, Stella X. and Ji, Na},
	title = {Adaptive optical correction in in vivo two-photon fluorescence microscopy with neural fields},
	elocation-id = {2024.10.20.619284},
	year = {2024},
	doi = {10.1101/2024.10.20.619284},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Adaptive optics (AO) techniques are designed to restore ideal imaging performance by measuring and correcting aberrations originating from both the microscope system and the sample itself. Conventional AO methods require additional hardware, such as wavefront sensors and corrective devices, for aberration measurement and correction, respectively. These methods often necessitate microscopes to adhere to strict design parameters, like perfect optical conjugation, to ensure the accurate delivery of corrective patterns for wavefront correction using corrective devices. However, in general microscope systems, including commercially available ones, conjugation errors are more prone to arise due to incomplete conjugation among optical components by design and misalignment of the components, coupled with their limited access and adjustability, which hinders the rigorous integration of AO hardware. Here, we describe a general-purpose AO framework using neural fields, NeAT, that is applicable to both custom-built and commercial two-photon fluorescence microscopes and demonstrate its performance in various in vivo imaging settings. This framework estimates wavefront aberration from a single 3D two-photon fluorescence image stack, without requiring external datasets for training. Additionally, it addresses the issue of incomplete optical conjugation by estimating and correcting any conjugation errors, which enables more accurate aberration correction by the corrective device. Finally, it jointly recovers the sample{\textquoteright}s 3D structural information during the learning process, potentially eliminating the need for hardware-based AO correction. We first carefully assess its aberration estimation performance using a custom-built two-photon fluorescence microscope equipped with a wavefront sensor which provides the ground truth aberration for comparison. We further characterize and assess the robustness of the aberration estimation to image stacks with low signal-to-noise ratios, strong aberration, and motion artifacts. As practical applications, using a commercial microscope with a spatial light modulator, we first demonstrate NeAT{\textquoteright}s real-time aberration correction performance in in vivo morphological imaging of the mouse brain. We further show its performance in in vivo functional activity imaging of glutamate and calcium dynamics within the mouse brain.Competing Interest StatementI.K. and N.J. are listed as inventors on a patent related to the technology described in this study (U.S. patent application No. 63/707.628). No other authors declare competing interests.},
	URL = {https://www.biorxiv.org/content/early/2024/10/22/2024.10.20.619284},
	eprint = {https://www.biorxiv.org/content/early/2024/10/22/2024.10.20.619284.full.pdf},
	journal = {bioRxiv}
}

@article{Fersini2025,
	author = {Francesco Fersini and Alessandro Zunino and Pietro Morerio and Francesca Baldini and Alberto Diaspro and Martin J. Booth and Alessio Del Bue and Giuseppe Vicidomini},
	journal = {Biomed. Opt. Express},
	keywords = {Beam shaping; Image metrics; Imaging techniques; Optical systems; Spatial light modulators; Spatial resolution},
	number = {5},
	pages = {2135--2155},
	publisher = {Optica Publishing Group},
	title = {Wavefront estimation through structured detection in laser scanning microscopy},
	volume = {16},
	month = {May},
	year = {2025},
	url = {https://opg.optica.org/boe/abstract.cfm?URI=boe-16-5-2135},
	doi = {10.1364/BOE.559899},
	abstract = {Laser scanning microscopy (LSM) is the base of numerous advanced imaging techniques, including confocal laser scanning microscopy (CLSM), a widely used tool in life sciences research. However, its effective resolution is often compromised by optical aberrations, a common challenge in all optical systems. While adaptive optics (AO) can correct these aberrations, current methods face significant limitations: aberration estimation, which is central to any AO approach, typically requires specialized hardware or prolonged sample exposure, rendering these methods sample-invasive, and less user-friendly. In this study, we propose a simple and efficient AO strategy for CLSM systems equipped with a detector array -- image-scanning microscopy -- and an AO element for beam shaping. We demonstrate, for the first time, that datasets acquired with a detector array inherently encode aberration information. As a proof-of-concept of this important property, we designed a custom convolutional neural network capable of decoding aberrations up to the 11th Zernike coefficient, directly from a single acquisition. While this data-driven approach represents an initial exploration of the aberration content, it opens the door to more advanced decoding strategies -- including model-based methods. This work establishes a new paradigm for aberration sensing in LSM and is designed to work synergistically with conventional AO approaches such as phase diversity, enabling faster, less invasive, and more accessible high-resolution imaging.},
}

@article{Zhou2023,
	author = {Zhou, You and Jin, Zhouyu and Zhao, Qianhui and Xiong, Bo and Cao, Xun},
	title = {Aberration Modeling in Deep Learning for Volumetric Reconstruction of Light-Field Microscopy},
	journal = {Laser \& Photonics Reviews},
	volume = {17},
	number = {10},
	pages = {2300154},
	keywords = {deep learning, light-field microscopy, spherical aberration modeling, volumetric imaging},
	doi = {https://doi.org/10.1002/lpor.202300154},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/lpor.202300154},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/lpor.202300154},
	abstract = {Abstract Optical aberration is a crucial issue in optical microscopes, fundamentally constraining the achievable imaging performance. As a commonly encountered one, spherical aberration is introduced by the refractive index mismatches between samples and their surrounding environments, leading to problems like low contrast, blurring, and distortion in imaging. Light-field microscopy (LFM) has recently emerged as a powerful tool for rapid volumetric imaging. The presence of spherical aberration in LFM will cause substantial changes of the point spread function (PSF) and thus greatly affects the imaging performance. Here, the aberration-modeling view-channel-depth (AM-VCD) network is proposed for LFM reconstruction, effectively mitigating the influence of severe spherical aberration. By quantitatively estimating the spherical aberration in advance and incorporating it into the network training, the AM-VCD achieves aberration-corrected high-speed visualization of 3D processes with uniform spatial resolution and real-time reconstruction speed. Without necessitating hardware modifications, this method provides a convenient way for directly observing the 3D dynamics of samples in solution. The capability of AM-VCD under a large refractive index mismatch is demonstrated through volumetric imaging of a large-scale fishbone of a largemouth bass. Furthermore, the capability of AM-VCD in nearly 100 Hz volumetric imaging of neutrophil migration and a beating heart in living zebrafish is investigated.},
	year = {2023}
}

@article{Qiao2024,
	author = {Chang Qiao and Haoyu Chen and Run Wang and Tao Jiang and Yuwang Wang and Dong Li},
	journal = {Photon. Res.},
	keywords = {Deformable mirrors; Imaging systems; Optical aberration; Spatial light modulators; Spatial resolution; Spherical aberration},
	number = {3},
	pages = {474--484},
	publisher = {Optica Publishing Group},
	title = {Deep learning-based optical aberration estimation enables offline digital adaptive optics and super-resolution imaging},
	volume = {12},
	month = {Mar},
	year = {2024},
	url = {https://opg.optica.org/prj/abstract.cfm?URI=prj-12-3-474},
	doi = {10.1364/PRJ.506778},
	abstract = {Optical aberrations degrade the performance of fluorescence microscopy. Conventional adaptive optics (AO) leverages specific devices, such as the Shack\&\#x2013;Hartmann wavefront sensor and deformable mirror, to measure and correct optical aberrations. However, conventional AO requires either additional hardware or a more complicated imaging procedure, resulting in higher cost or a lower acquisition speed. In this study, we proposed a novel space-frequency encoding network (SFE-Net) that can directly estimate the aberrated point spread functions (PSFs) from biological images, enabling fast optical aberration estimation with high accuracy without engaging extra optics and image acquisition. We showed that with the estimated PSFs, the optical aberration can be computationally removed by the deconvolution algorithm. Furthermore, to fully exploit the benefits of SFE-Net, we incorporated the estimated PSF with neural network architecture design to devise an aberration-aware deep-learning super-resolution model, dubbed SFT-DFCAN. We demonstrated that the combination of SFE-Net and SFT-DFCAN enables instant digital AO and optical aberration-aware super-resolution reconstruction for live-cell imaging.},
}

@article{Hu2021,
	author = {Lejia Hu and Shuwen Hu and Wei Gong and Ke Si},
	journal = {Opt. Lett.},
	keywords = {Deep learning; Fluorescence microscopy; High speed imaging; Image enhancement; Multiphoton microscopy; Spatial light modulators},
	number = {9},
	pages = {2055--2058},
	publisher = {Optica Publishing Group},
	title = {Image enhancement for fluorescence microscopy based on deep learning with prior knowledge of aberration},
	volume = {46},
	month = {May},
	year = {2021},
	url = {https://opg.optica.org/ol/abstract.cfm?URI=ol-46-9-2055},
	doi = {10.1364/OL.418997},
	abstract = {In this Letter, we propose a deep learning method with prior knowledge of potential aberration to enhance the fluorescence microscopy without additional hardware. The proposed method could effectively reduce noise and improve the peak signal-to-noise ratio of the acquired images at high speed. The enhancement performance and generalization of this method is demonstrated on three commercial fluorescence microscopes. This work provides a computational alternative to overcome the degradation induced by the biological specimen, and it has the potential to be further applied in biological applications.},
}

@article{Wang2019,
	author={Wang, Hongda 	and Rivenson, Yair	and Jin, Yiyin	and Wei, Zhensong	and Gao, Ronald	and G{\"u}nayd{\i}n, Harun	and Bentolila, Laurent A.	and Kural, Comert	and Ozcan, Aydogan},
	title={Deep learning enables cross-modality super-resolution in fluorescence microscopy},
	journal={Nature Methods},
	year={2019},
	month={Jan},
	day={01},
	volume={16},
	number={1},
	pages={103-110},
	abstract={We present deep-learning-enabled super-resolution across different fluorescence microscopy modalities. This data-driven approach does not require numerical modeling of the imaging process or the estimation of a point-spread-function, and is based on training a generative adversarial network (GAN) to transform diffraction-limited input images into super-resolved ones. Using this framework, we improve the resolution of wide-field images acquired with low-numerical-aperture objectives, matching the resolution that is acquired using high-numerical-aperture objectives. We also demonstrate cross-modality super-resolution, transforming confocal microscopy images to match the resolution acquired with a stimulated emission depletion (STED) microscope. We further demonstrate that total internal reflection fluorescence (TIRF) microscopy images of subcellular structures within cells and tissues can be transformed to match the results obtained with a TIRF-based structured illumination microscope. The deep network rapidly outputs these super-resolved images, without any iterations or parameter search, and could serve to democratize super-resolution imaging.},
	issn={1548-7105},
	doi={10.1038/s41592-018-0239-0},
	url={https://doi.org/10.1038/s41592-018-0239-0}
}

@article{Park2022,
	author={Park, Hyoungjun	and Na, Myeongsu	and Kim, Bumju	and Park, Soohyun	and Kim, Ki Hean	and Chang, Sunghoe	and Ye, Jong Chul},
	title={Deep learning enables reference-free isotropic super-resolution for volumetric fluorescence microscopy},
	journal={Nature Communications},
	year={2022},
	month={Jun},
	day={08},
	volume={13},
	number={1},
	pages={3297},
	abstract={Volumetric imaging by fluorescence microscopy is often limited by anisotropic spatial resolution, in which the axial resolution is inferior to the lateral resolution. To address this problem, we present a deep-learning-enabled unsupervised super-resolution technique that enhances anisotropic images in volumetric fluorescence microscopy. In contrast to the existing deep learning approaches that require matched high-resolution target images, our method greatly reduces the effort to be put into practice as the training of a network requires only a single 3D image stack, without a priori knowledge of the image formation process, registration of training data, or separate acquisition of target data. This is achieved based on the optimal transport-driven cycle-consistent generative adversarial network that learns from an unpaired matching between high-resolution 2D images in the lateral image plane and low-resolution 2D images in other planes. Using fluorescence confocal microscopy and light-sheet microscopy, we demonstrate that the trained network not only enhances axial resolution but also restores suppressed visual details between the imaging planes and removes imaging artifacts.},
	issn={2041-1723},
	doi={10.1038/s41467-022-30949-6},
	url={https://doi.org/10.1038/s41467-022-30949-6}
}

@article{Ning2023,
	author={Ning, Kefu	and Lu, Bolin	and Wang, Xiaojun	and Zhang, Xiaoyu	and Nie, Shuo	and Jiang, Tao	and Li, Anan	and Fan, Guoqing	and Wang, Xiaofeng	and Luo, Qingming	and Gong, Hui	and Yuan, Jing},
	title={Deep self-learning enables fast, high-fidelity isotropic resolution restoration for volumetric fluorescence microscopy},
	journal={Light: Science {\&} Applications},
	year={2023},
	month={Aug},
	day={28},
	volume={12},
	number={1},
	pages={204},
	abstract={One intrinsic yet critical issue that troubles the field of fluorescence microscopy ever since its introduction is the unmatched resolution in the lateral and axial directions (i.e., resolution anisotropy), which severely deteriorates the quality, reconstruction, and analysis of 3D volume images. By leveraging the natural anisotropy, we present a deep self-learning method termed Self-Net that significantly improves the resolution of axial images by using the lateral images from the same raw dataset as rational targets. By incorporating unsupervised learning for realistic anisotropic degradation and supervised learning for high-fidelity isotropic recovery, our method can effectively suppress the hallucination with substantially enhanced image quality compared to previously reported methods. In the experiments, we show that Self-Net can reconstruct high-fidelity isotropic 3D images from organelle to tissue levels via raw images from various microscopy platforms, e.g., wide-field, laser-scanning, or super-resolution microscopy. For the first time, Self-Net enables isotropic whole-brain imaging at a voxel resolution of 0.2{\thinspace}{\texttimes}{\thinspace}0.2{\thinspace}{\texttimes}{\thinspace}0.2{\thinspace}$\mu$m3, which addresses the last-mile problem of data quality in single-neuron morphology visualization and reconstruction with minimal effort and cost. Overall, Self-Net is a promising approach to overcoming the inherent resolution anisotropy for all classes of 3D fluorescence microscopy.},
	issn={2047-7538},
	doi={10.1038/s41377-023-01230-2},
	url={https://doi.org/10.1038/s41377-023-01230-2}
}

@InProceedings{Ronneberger2015,
	author="Ronneberger, Olaf	and Fischer, Philipp	and Brox, Thomas",
	editor="Navab, Nassir
	and Hornegger, Joachim
	and Wells, William M.
	and Frangi, Alejandro F.",
	title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
	booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
	year="2015",
	publisher="Springer International Publishing",
	address="Cham",
	pages="234--241",
	abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
	isbn="978-3-319-24574-4"
}

@inproceedings{Ji2021,
	title = "Early-stopped neural networks are consistent",
	abstract = "This work studies the behavior of shallow ReLU networks trained with the logistic loss via gradient descent on binary classification data where the underlying data distribution is general, and the (optimal) Bayes risk is not necessarily zero. In this setting, it is shown that gradient descent with early stopping achieves population risk arbitrarily close to optimal in terms of not just logistic and misclassification losses, but also in terms of calibration, meaning the sigmoid mapping of its outputs approximates the true underlying conditional distribution arbitrarily finely. Moreover, the necessary iteration, sample, and architectural complexities of this analysis all scale naturally with a certain complexity measure of the true conditional model. Lastly, while it is not shown that early stopping is necessary, it is shown that any univariate classifier satisfying a local interpolation property is inconsistent.",
	author = "Ziwei Ji and Li, \{Justin D.\} and Matus Telgarsky",
	note = "Publisher Copyright: {\textcopyright} 2021 Neural information processing systems foundation. All rights reserved.; 35th Conference on Neural Information Processing Systems, NeurIPS 2021 ; Conference date: 06-12-2021 Through 14-12-2021",
	year = "2021",
	language = "English (US)",
	series = "Advances in Neural Information Processing Systems",
	publisher = "Neural information processing systems foundation",
	pages = "1805--1817",
	editor = "Marc'Aurelio Ranzato and Alina Beygelzimer and Yann Dauphin and Liang, \{Percy S.\} and \{Wortman Vaughan\}, Jenn",
	booktitle = "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
}

@article{Santos2022,
	author = {Santos, Claudio Filipi Gon\c{c}alves Dos and Papa, Jo\~{a}o Paulo},
	title = {Avoiding Overfitting: A Survey on Regularization Methods for Convolutional Neural Networks},
	year = {2022},
	issue_date = {January 2022},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {54},
	number = {10s},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3510413},
	doi = {10.1145/3510413},
	abstract = {Several image processing tasks, such as image classification and object detection, have been significantly improved using Convolutional Neural Networks (CNN). Like ResNet and EfficientNet, many architectures have achieved outstanding results in at least one dataset by the time of their creation. A critical factor in training concerns the network’s regularization, which prevents the structure from overfitting. This work analyzes several regularization methods developed in the past few years, showing significant improvements for different CNN models. The works are classified into three main areas: the first one is called “data augmentation,” where all the techniques focus on performing changes in the input data. The second, named “internal changes,” aims to describe procedures to modify the feature maps generated by the neural network or the kernels. The last one, called “label,” concerns transforming the labels of a given input. This work presents two main differences comparing to other available surveys about regularization: (i) the first concerns the papers gathered in the manuscript, which are not older than five years, and (ii) the second distinction is about reproducibility, i.e., all works referred here have their code available in public repositories or they have been directly implemented in some framework, such as TensorFlow or Torch.},
	journal = {ACM Comput. Surv.},
	month = sep,
	articleno = {213},
	numpages = {25},
	keywords = {Regularization, convolutional neural networks}
}

@article{Miseta2024,
	title = {Surpassing early stopping: A novel correlation-based stopping criterion for neural networks},
	journal = {Neurocomputing},
	volume = {567},
	pages = {127028},
	year = {2024},
	issn = {0925-2312},
	doi = {https://doi.org/10.1016/j.neucom.2023.127028},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231223011517},
	author = {Tamás Miseta and Attila Fodor and Ágnes Vathy-Fogarassy},
	keywords = {Neural network, Stopping criterion, Early stopping, Correlation-Driven Stopping Criterion, Regularization, Pearson correlation},
	abstract = {During the training of neural networks, selecting the right stopping criterion is crucial to prevent overfitting and conserve computing power. While the early stopping and the maximum number of epochs stopping methods are simple to implement, they have limitations in identifying the point during training where the training and the validation loss start to diverge. To overcome these limitations, we propose a general correlation-based stopping criterion called the Correlation-Driven Stopping Criterion (CDSC). The CDSC stops the training process when the rolling Pearson correlation of the loss metrics between the training and validation datasets decreases below a pre-defined threshold. To show the effectiveness of the newly proposed Correlation-Driven Stopping Criterion, its effectiveness was compared with the effectiveness of the early stopping and the maximum number of epochs stopping methods across multiple common machine learning problems and neural network models. Our study shows that the proposed Correlation-Driven Stopping Criterion can enhance the out-of-sample performance of all tested neural network models while conserving computing power.}
}

@ARTICLE{Shah2024,  
	AUTHOR={Shah, Zafran Hussain  and Müller, Marcel  and Hübner, Wolfgang  and Ortkrass, Henning  and Hammer, Barbara  and Huser, Thomas  and Schenck, Wolfram },         
	TITLE={Image restoration in frequency space using complex-valued CNNs},        
	JOURNAL={Frontiers in Artificial Intelligence},        
	VOLUME={Volume 7 - 2024},
	YEAR={2024},
	URL={https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1353873},
	DOI={10.3389/frai.2024.1353873},
	ISSN={2624-8212},
	ABSTRACT={Real-valued convolutional neural networks (RV-CNNs) in the spatial domain have outperformed classical approaches in many image restoration tasks such as image denoising and super-resolution. Fourier analysis of the results produced by these spatial domain models reveals the limitations of these models in properly processing the full frequency spectrum. This lack of complete spectral information can result in missing textural and structural elements. To address this limitation, we explore the potential of complex-valued convolutional neural networks (CV-CNNs) for image restoration tasks. CV-CNNs have shown remarkable performance in tasks such as image classification and segmentation. However, CV-CNNs for image restoration problems in the frequency domain have not been fully investigated to address the aforementioned issues. Here, we propose several novel CV-CNN-based models equipped with complex-valued attention gates for image denoising and super-resolution in the frequency domains. We also show that our CV-CNN-based models outperform their real-valued counterparts for denoising super-resolution structured illumination microscopy (SR-SIM) and conventional image datasets. Furthermore, the experimental results show that our proposed CV-CNN-based models preserve the frequency spectrum better than their real-valued counterparts in the denoising task. Based on these findings, we conclude that CV-CNN-based methods provide a plausible and beneficial deep learning approach for image restoration in the frequency domain.}
}

@article{Zhang2019,
	author = {Chong Zhang and Kun Wang and Yu An and Kunshan He and Tong Tong and Jie Tian},
	journal = {Biomed. Opt. Express},
	keywords = {Biomedical imaging; Imaging systems; Light diffraction; Optical imaging; Optical properties; Spatial resolution},
	number = {9},
	pages = {4742--4756},
	publisher = {Optica Publishing Group},
	title = {Improved generative adversarial networks using the total gradient loss for the resolution enhancement of fluorescence images},
	volume = {10},
	month = {Sep},
	year = {2019},
	url = {https://opg.optica.org/boe/abstract.cfm?URI=boe-10-9-4742},
	doi = {10.1364/BOE.10.004742},
	abstract = {Because of the optical properties of medical fluorescence images (FIs) and hardware limitations, light scattering and diffraction constrain the image quality and resolution. In contrast to device-based approaches, we developed a post-processing method for FI resolution enhancement by employing improved generative adversarial networks. To overcome the drawback of fake texture generation, we proposed total gradient loss for network training. Fine-tuning training procedure was applied to further improve the network architecture. Finally, a more agreeable network for resolution enhancement was applied to actual FIs to produce sharper and clearer boundaries than in the original images.},
}

@article{Liu2024,
	AUTHOR = {Liu, Jihong and Gao, Fei and Zhang, Lvheng and Yang, Haixu},
	TITLE = {A Saturation Artifacts Inpainting Method Based on Two-Stage GAN for Fluorescence Microscope Images},
	JOURNAL = {Micromachines},
	VOLUME = {15},
	YEAR = {2024},
	NUMBER = {7},
	ARTICLE-NUMBER = {928},
	URL = {https://www.mdpi.com/2072-666X/15/7/928},
	PubMedID = {39064439},
	ISSN = {2072-666X},
	ABSTRACT = {Fluorescence microscopic images of cells contain a large number of morphological features that are used as an unbiased source of quantitative information about cell status, through which researchers can extract quantitative information about cells and study the biological phenomena of cells through statistical and analytical analysis. As an important research object of phenotypic analysis, images have a great influence on the research results. Saturation artifacts present in the image result in a loss of grayscale information that does not reveal the true value of fluorescence intensity. From the perspective of data post-processing, we propose a two-stage cell image recovery model based on a generative adversarial network to solve the problem of phenotypic feature loss caused by saturation artifacts. The model is capable of restoring large areas of missing phenotypic features. In the experiment, we adopt the strategy of progressive restoration to improve the robustness of the training effect and add the contextual attention structure to enhance the stability of the restoration effect. We hope to use deep learning methods to mitigate the effects of saturation artifacts to reveal how chemical, genetic, and environmental factors affect cell state, providing an effective tool for studying the field of biological variability and improving image quality in analysis.},
	DOI = {10.3390/mi15070928}
}

@article{Bouchard2023,
	author={Bouchard, Catherine	and Wiesner, Theresa	and Desch{\^e}nes, Andr{\'e}anne	and Bilodeau, Anthony	and Turcotte, Beno{\^i}t	and Gagn{\'e}, Christian	and Lavoie-Cardinal, Flavie},
	title={Resolution enhancement with a task-assisted GAN to guide optical nanoscopy image analysis and acquisition},
	journal={Nature Machine Intelligence},
	year={2023},
	month={Aug},
	day={01},
	volume={5},
	number={8},
	pages={830-844},
	abstract={Super-resolution fluorescence microscopy methods enable the characterization of nanostructures in living and fixed biological tissues. However, they require the adjustment of multiple imaging parameters while attempting to satisfy conflicting objectives, such as maximizing spatial and temporal resolution while minimizing light exposure. To overcome the limitations imposed by these trade-offs, post-acquisition algorithmic approaches have been proposed for resolution enhancement and image-quality improvement. Here we introduce the task-assisted generative adversarial network (TA-GAN), which incorporates an auxiliary task (for example, segmentation, localization) closely related to the observed biological nanostructure characterization. We evaluate how the TA-GAN improves generative accuracy over unassisted methods, using images acquired with different modalities such as confocal, bright-field, stimulated emission depletion and structured illumination microscopy. The TA-GAN is incorporated directly into the acquisition pipeline of the microscope to predict the nanometric content of the field of view without requiring the acquisition of a super-resolved image. This information is used to automatically select the imaging modality and regions of interest, optimizing the acquisition sequence by reducing light exposure. Data-driven microscopy methods like the TA-GAN will enable the observation of dynamic molecular processes with spatial and temporal resolutions that surpass the limits currently imposed by the trade-offs constraining super-resolution microscopy.},
	issn={2522-5839},
	doi={10.1038/s42256-023-00689-3},
	url={https://doi.org/10.1038/s42256-023-00689-3}
}

@Article{Qiao2023,
	author={Qiao, Chang	and Li, Di	and Liu, Yong	and Zhang, Siwei	and Liu, Kan	and Liu, Chong	and Guo, Yuting	and Jiang, Tao	and Fang, Chuyu	and Li, Nan	and Zeng, Yunmin	and He, Kangmin	and Zhu, Xueliang	and Lippincott-Schwartz, Jennifer	and Dai, Qionghai	and Li, Dong},
	title={Rationalized deep learning super-resolution microscopy for sustained live imaging of rapid subcellular processes},
	journal={Nature Biotechnology},
	year={2023},
	month={Mar},
	day={01},
	volume={41},
	number={3},
	pages={367-377},
	abstract={The goal when imaging bioprocesses with optical microscopy is to acquire the most spatiotemporal information with the least invasiveness. Deep neural networks have substantially improved optical microscopy, including image super-resolution and restoration, but still have substantial potential for artifacts. In this study, we developed rationalized deep learning (rDL) for structured illumination microscopy and lattice light sheet microscopy (LLSM) by incorporating prior knowledge of illumination patterns and, thereby, rationally guiding the network to denoise raw images. Here we demonstrate that rDL structured illumination microscopy eliminates spectral bias-induced resolution degradation and reduces model uncertainty by five-fold, improving the super-resolution information by more than ten-fold over other computational approaches. Moreover, rDL applied to LLSM enables self-supervised training by using the spatial or temporal continuity of noisy data itself, yielding results similar to those of supervised methods. We demonstrate the utility of rDL by imaging the rapid kinetics of motile cilia, nucleolar protein condensation during light-sensitive mitosis and long-term interactions between membranous and membrane-less organelles.},
	issn={1546-1696},
	doi={10.1038/s41587-022-01471-3},
	url={https://doi.org/10.1038/s41587-022-01471-3}
}

@inproceedings{Zhong2021,
  author={Liqun Zhong and Guole Liu and Ge Yang},
  title={Blind Denoising of Fluorescence Microscopy Images Using GAN-Based Global Noise Modeling},
  year={2021},
  cdate={1609459200000},
  pages={863-867},
  url={https://doi.org/10.1109/ISBI48211.2021.9434150},
  booktitle={ISBI},
  crossref={conf/isbi/2021}
}

@article{Park2024,
	author={Park, Eunwoo	and Misra, Sampa	and Hwang, Dong Gyu	and Yoon, Chiho	and Ahn, Joongho	and Kim, Donggyu	and Jang, Jinah	and Kim, Chulhong},
	title={Unsupervised inter-domain transformation for virtually stained high-resolution mid-infrared photoacoustic microscopy using explainable deep learning},
	journal={Nature Communications},
	year={2024},
	month={Dec},
	day={30},
	volume={15},
	number={1},
	pages={10892},
	abstract={Mid-infrared photoacoustic microscopy can capture biochemical information without staining. However, the long mid-infrared optical wavelengths make the spatial resolution of photoacoustic microscopy significantly poorer than that of conventional confocal fluorescence microscopy. Here, we demonstrate an explainable deep learning-based unsupervised inter-domain transformation of low-resolution unlabeled mid-infrared photoacoustic microscopy images into confocal-like virtually fluorescence-stained high-resolution images. The explainable deep learning-based framework is proposed for this transformation, wherein an unsupervised generative adversarial network is primarily employed and then a saliency constraint is added for better explainability. We validate the performance of explainable deep learning-based mid-infrared photoacoustic microscopy by identifying cell nuclei and filamentous actins in cultured human cardiac fibroblasts and matching them with the corresponding CFM images. The XDL ensures similar saliency between the two domains, making the transformation process more stable and more reliable than existing networks. Our XDL-MIR-PAM enables label-free high-resolution duplexed cellular imaging, which can significantly benefit many research avenues in cell biology.},
	issn={2041-1723},
	doi={10.1038/s41467-024-55262-2},
	url={https://doi.org/10.1038/s41467-024-55262-2}
}

@INPROCEEDINGS{Osuna-Vargas2025,
	author={Osuna-Vargas, Pamela and Wehrheim, Maren H. and Zinz, Lucas and Rahm, Johanna and Balakrishnan, Ashwin and Kaminer, Alexandra and Heilemann, Mike and Kaschube, Matthias},
	booktitle={2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
	title={Denoising Diffusion Models for High-Resolution Microscopy Image Restoration}, 
	year={2025},
	volume={},
	number={},
	pages={4320-4330},
	keywords={Training;Image resolution;Microscopy;Noise reduction;Stochastic processes;Diffusion models;Probabilistic logic;Reliability;Signal resolution;Signal to noise ratio;image denoising;image restoration;fluorescence microscopy;generative models;denoising diffusion probabilistic models},
	doi={10.1109/WACV61041.2025.00424}
  }

@misc{Zhang2018,
	title={Image Super-Resolution Using Very Deep Residual Channel Attention Networks}, 
	author={Yulun Zhang and Kunpeng Li and Kai Li and Lichen Wang and Bineng Zhong and Yun Fu},
	year={2018},
	eprint={1807.02758},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/1807.02758}, 
}

@ARTICLE{Wang2004,
  author={Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
  journal={IEEE Transactions on Image Processing}, 
  title={Image quality assessment: from error visibility to structural similarity}, 
  year={2004},
  volume={13},
  number={4},
  pages={600-612},
  keywords={Image quality;Humans;Transform coding;Visual system;Visual perception;Data mining;Layout;Quality assessment;Degradation;Indexes},
  doi={10.1109/TIP.2003.819861}
}

Need to confirm that this is correct:
17.	Gonzalez, R.C. and R.E. Woods, Digital image processing. IEEE Transactions on Acoustics Speech and Signal Processing, 1980. 28(4): p. 484-486.
@book{Gonzalez1992,
  title={Digital Image Processing},
  author={Gonzalez, R.C. and Woods, R.E.},
  isbn={9780201508031},
  lccn={91030866},
  series={Addison-Wesley world student series},
  url={https://books.google.com/books?id=C_FRAAAAMAAJ},
  year={1992},
  publisher={Addison-Wesley}
}
