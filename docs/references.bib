@article{stringer2021,
	title = {Cellpose: a generalist algorithm for cellular segmentation},
	volume = {18},
	issn = {1548-7105},
	shorttitle = {Cellpose},
	url = {https://www.nature.com/articles/s41592-020-01018-x},
	doi = {10.1038/s41592-020-01018-x},
	language = {en},
	number = {1},
	urldate = {2024-06-03},
	journal = {Nature Methods},
	author = {Stringer, Carsen and Wang, Tim and Michaelos, Michalis and Pachitariu, Marius},
	month = jan,
	year = {2021},
  publisher = {Nature Publishing Group},
	pages = {100--106}
  }

@article{von_chamier2021,
	title = {Democratising deep learning for microscopy with {ZeroCostDL4Mic}},
	volume = {12},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-22518-0},
	doi = {10.1038/s41467-021-22518-0},
	language = {en},
	number = {1},
	urldate = {2022-06-24},
	journal = {Nature Communications},
	author = {von Chamier, Lucas and Laine, Romain F. and Jukkala, Johanna and Spahn, Christoph and Krentzel, Daniel and Nehme, Elias and Lerche, Martina and Hernández-Pérez, Sara and Mattila, Pieta K. and Karinou, Eleni and Holden, Séamus and Solak, Ahmet Can and Krull, Alexander and Buchholz, Tim-Oliver and Jones, Martin L. and Royer, Loïc A. and Leterrier, Christophe and Shechtman, Yoav and Jug, Florian and Heilemann, Mike and Jacquemet, Guillaume and Henriques, Ricardo},
	month = apr,
	year = {2021},
  ublisher = {Nature Publishing Group},
	pages = {2276},
}

@article{guo_deep_2025,
	title = {Deep learning-based aberration compensation improves contrast and resolution in fluorescence microscopy},
	volume = {16},
	issn = {2041-1723},
	url = {https://doi.org/10.1038/s41467-024-55267-x},
	doi = {10.1038/s41467-024-55267-x},
	abstract = {Optical aberrations hinder fluorescence microscopy of thick samples, reducing image signal, contrast, and resolution. Here we introduce a deep learning-based strategy for aberration compensation, improving image quality without slowing image acquisition, applying additional dose, or introducing more optics. Our method (i) introduces synthetic aberrations to images acquired on the shallow side of image stacks, making them resemble those acquired deeper into the volume and (ii) trains neural networks to reverse the effect of these aberrations. We use simulations and experiments to show that applying the trained ‘de-aberration’ networks outperforms alternative methods, providing restoration on par with adaptive optics techniques; and subsequently apply the networks to diverse datasets captured with confocal, light-sheet, multi-photon, and super-resolution microscopy. In all cases, the improved quality of the restored data facilitates qualitative image inspection and improves downstream image quantitation, including orientational analysis of blood vessels in mouse tissue and improved membrane and nuclear segmentation in C. elegans embryos.},
	number = {1},
	journal = {Nature Communications},
	author = {Guo, Min and Wu, Yicong and Hobson, Chad M. and Su, Yijun and Qian, Shuhao and Krueger, Eric and Christensen, Ryan and Kroeschell, Grant and Bui, Johnny and Chaw, Matthew and Zhang, Lixia and Liu, Jiamin and Hou, Xuekai and Han, Xiaofei and Lu, Zhiye and Ma, Xuefei and Zhovmer, Alexander and Combs, Christian and Moyle, Mark and Yemini, Eviatar and Liu, Huafeng and Liu, Zhiyi and Benedetto, Alexandre and La Riviere, Patrick and Colón-Ramos, Daniel and Shroff, Hari},
	month = jan,
	year = {2025},
	pages = {313},
}

@ARTICLE{Haase2024,
  title    = "A call for {FAIR} and open-access training materials to advance
              {BioImage} Analysis",
  author   = "Haase, Robert and Tischer, Christian and Bankhead, Peter and
              Miura, Kota and Cimini, Beth",
  abstract = "Interdisciplinary communities, such as the life-sciences, have a
              strong need for efficient knowledge-transfer. In our community,
              computer scientists, bioimage analysts and biologists frequently
              come together to train each other in quantitative microscopy
              bioimage data analysis. For these trainings, re-usable
              high-quality training materials can be key. We advocate for
              publishing training materials according to the FAIR principles:
              Materials must be findable, openly accessible, stored in
              interoperable file formats, and most importantly made reusable by
              attaching open-access licenses. We are convinced that the path
              towards FAIR training materials leads us to more advanced and
              higher quality training, facilitating the advance of BioImage
              Analysis as a whole.",
  month    =  mar,
  year     =  2024
}

@ARTICLE{Ljosa2012,
  title    = "Annotated high-throughput microscopy image sets for validation",
  author   = "Ljosa, Vebjorn and Sokolnicki, Katherine L and Carpenter, Anne E",
  journal  = "Nat. Methods",
  volume   =  9,
  number   =  7,
  pages    =  637,
  month    =  jun,
  year     =  2012,
  language = "en"
}

@MISC{Cimini2019,
  title     = "When to say 'good enough'",
  author    = "Cimini, Beth A",
  publisher = "Zenodo",
  abstract  = "Blog post from the ``Measure Everything... Ask Questions Later''
               blog of the Broad Institute Imaging Platform",
  month     =  oct,
  year      =  2019
}

@ARTICLE{Jamali2021,
  title     = "2020 {BioImage} Analysis Survey: Community experiences and needs
               for the future",
  author    = "Jamali, Nasim and Dobson, Ellen T A and Eliceiri, Kevin W and
               Carpenter, Anne E and Cimini, Beth A",
  journal   = "Biological Imaging",
  publisher = "Cambridge University Press",
  volume    =  1,
  pages     = "e4",
  abstract  = "In this paper, we summarize a global survey of 484 participants
               of the imaging community, conducted in 2020 through the
               NIH-funded Center for Open Bioimage Analysis (COBA). This
               23-question survey covered experience with image analysis,
               scientific background and demographics, and views and requests
               from different members of the imaging community. Through
               open-ended questions, we asked the community to provide feedback
               for the open-source tool developers and tool user groups. The
               community’s requests for tool developers include general
               improvement of tool documentation and easy-to-follow tutorials.
               Respondents encourage tool users to follow the best practice
               guidelines for imaging and ask their image analysis questions on
               the Scientific Community Image Forum (forum.image.sc). We
               analyzed the community’s preferred method of learning based on
               level of computational proficiency and work description. In
               general, written step-by-step and video tutorials are preferred
               methods of learning by the community, followed by interactive
               webinars and office hours with an expert. There is also
               enthusiasm for a centralized online location for existing
               educational resources. The survey results will help the
               community, especially developers, trainers, and organizations
               like COBA, decide how to structure and prioritize their efforts.",
  month     =  jan,
  year      =  2021,
  keywords  = "Bioimage analysis; community; open-source software; survey;
               training"
}

@ARTICLE{Sivagurunathan2023,
  title    = "Bridging imaging users to imaging analysis - A community survey",
  author   = "Sivagurunathan, Suganya and Marcotti, Stefania and Nelson, Carl J
              and Jones, Martin L and Barry, David J and Slater, Thomas J A and
              Eliceiri, Kevin W and Cimini, Beth A",
  journal  = "J. Microsc.",
  abstract = "The 'Bridging Imaging Users to Imaging Analysis' survey was
              conducted in 2022 by the Center for Open Bioimage Analysis (COBA),
              BioImaging North America (BINA) and the Royal Microscopical
              Society Data Analysis in Imaging Section (RMS DAIM) to understand
              the needs of the imaging community. Through multichoice and
              open-ended questions, the survey inquired about demographics,
              image analysis experiences, future needs and suggestions on the
              role of tool developers and users. Participants of the survey were
              from diverse roles and domains of the life and physical sciences.
              To our knowledge, this is the first attempt to survey
              cross-community to bridge knowledge gaps between physical and life
              sciences imaging. Survey results indicate that respondents'
              overarching needs are documentation, detailed tutorials on the
              usage of image analysis tools, user-friendly intuitive software,
              and better solutions for segmentation, ideally in a format
              tailored to their specific use cases. The tool creators suggested
              the users familiarise themselves with the fundamentals of image
              analysis, provide constant feedback and report the issues faced
              during image analysis while the users would like more
              documentation and an emphasis on tool friendliness. Regardless of
              the computational experience, there is a strong preference for
              'written tutorials' to acquire knowledge on image analysis. We
              also observed that the interest in having 'office hours' to get an
              expert opinion on their image analysis methods has increased over
              the years. The results also showed less-than-expected usage of
              online discussion forums in the imaging community for solving
              image analysis problems. Surprisingly, we also observed a
              decreased interest among the survey respondents in deep/machine
              learning despite the increasing adoption of artificial
              intelligence in biology. In addition, the community suggests the
              need for a common repository for the available image analysis
              tools and their applications. The opinions and suggestions of the
              community, released here in full, will help the image analysis
              tool creation and education communities to design and deliver the
              resources accordingly.",
  month    =  sep,
  year     =  2023,
  keywords = "deep learning; image analysis; life science; physical science;
              survey",
  language = "en"
}

@ARTICLE{Schindelin2012,
  title    = "Fiji: an open-source platform for biological-image analysis",
  author   = "Schindelin, Johannes and Arganda-Carreras, Ignacio and Frise,
              Erwin and Kaynig, Verena and Longair, Mark and Pietzsch, Tobias
              and Preibisch, Stephan and Rueden, Curtis and Saalfeld, Stephan
              and Schmid, Benjamin and Tinevez, Jean-Yves and White, Daniel
              James and Hartenstein, Volker and Eliceiri, Kevin and Tomancak,
              Pavel and Cardona, Albert",
  journal  = "Nat. Methods",
  volume   =  9,
  number   =  7,
  pages    = "676--682",
  abstract = "Fiji is a distribution of the popular open-source software ImageJ
              focused on biological-image analysis. Fiji uses modern software
              engineering practices to combine powerful software libraries with
              a broad range of scripting languages to enable rapid prototyping
              of image-processing algorithms. Fiji facilitates the
              transformation of new algorithms into ImageJ plugins that can be
              shared with end users through an integrated update system. We
              propose Fiji as a platform for productive collaboration between
              computer science and biology research communities.",
  month    =  jun,
  year     =  2012,
  language = "en"
}

@ARTICLE{Schindelin2015,
  title     = "The {ImageJ} ecosystem: An open platform for biomedical image
               analysis",
  author    = "Schindelin, Johannes and Rueden, Curtis T and Hiner, Mark C and
               Eliceiri, Kevin W",
  journal   = "Mol. Reprod. Dev.",
  publisher = "Wiley",
  volume    =  82,
  number    = "7-8",
  pages     = "518--529",
  abstract  = "Technology in microscopy advances rapidly, enabling increasingly
               affordable, faster, and more precise quantitative biomedical
               imaging, which necessitates correspondingly more-advanced image
               processing and analysis techniques. A wide range of software is
               available-from commercial to academic, special-purpose to Swiss
               army knife, small to large-but a key characteristic of software
               that is suitable for scientific inquiry is its accessibility.
               Open-source software is ideal for scientific endeavors because it
               can be freely inspected, modified, and redistributed; in
               particular, the open-software platform ImageJ has had a huge
               impact on the life sciences, and continues to do so. From its
               inception, ImageJ has grown significantly due largely to being
               freely available and its vibrant and helpful user community.
               Scientists as diverse as interested hobbyists, technical
               assistants, students, scientific staff, and advanced biology
               researchers use ImageJ on a daily basis, and exchange knowledge
               via its dedicated mailing list. Uses of ImageJ range from data
               visualization and teaching to advanced image processing and
               statistical analysis. The software's extensibility continues to
               attract biologists at all career stages as well as computer
               scientists who wish to effectively implement specific
               image-processing algorithms. In this review, we use the ImageJ
               project as a case study of how open-source software fosters its
               suites of software tools, making multitudes of image-analysis
               technology easily accessible to the scientific community. We
               specifically explore what makes ImageJ so popular, how it impacts
               the life sciences, how it inspires other projects, and how it is
               self-influenced by coevolving projects within the ImageJ
               ecosystem.",
  month     =  jul,
  year      =  2015,
  language  = "en"
}

@MISC{napari,
  title = "napari: a multi-dimensional image viewer for Python",
  doi = {10.5281/zenodo.3555620}
}

@ARTICLE{Stirling2021,
  title    = "{CellProfiler} 4: improvements in speed, utility and usability",
  author   = "Stirling, David R and Swain-Bowden, Madison J and Lucas, Alice M
              and Carpenter, Anne E and Cimini, Beth A and Goodman, Allen",
  journal  = "BMC Bioinformatics",
  volume   =  22,
  number   =  1,
  pages    =  433,
  abstract = "BACKGROUND: Imaging data contains a substantial amount of
              information which can be difficult to evaluate by eye. With the
              expansion of high throughput microscopy methodologies producing
              increasingly large datasets, automated and objective analysis of
              the resulting images is essential to effectively extract
              biological information from this data. CellProfiler is a free,
              open source image analysis program which enables researchers to
              generate modular pipelines with which to process microscopy images
              into interpretable measurements. RESULTS: Herein we describe
              CellProfiler 4, a new version of this software with expanded
              functionality. Based on user feedback, we have made several user
              interface refinements to improve the usability of the software. We
              introduced new modules to expand the capabilities of the software.
              We also evaluated performance and made targeted optimizations to
              reduce the time and cost associated with running common
              large-scale analysis pipelines. CONCLUSIONS: CellProfiler 4
              provides significantly improved performance in complex workflows
              compared to previous versions. This release will ensure that
              researchers will have continued access to CellProfiler's powerful
              computational tools in the coming years.",
  month    =  sep,
  year     =  2021,
  keywords = "Bioimaging; Image analysis; Image quantitation; Image
              segmentation; Microscopy",
  language = "en"
}

@ARTICLE{Bankhead2017,
  title    = "{QuPath}: Open source software for digital pathology image
              analysis",
  author   = "Bankhead, Peter and Loughrey, Maurice B and Fernández, José A and
              Dombrowski, Yvonne and McArt, Darragh G and Dunne, Philip D and
              McQuaid, Stephen and Gray, Ronan T and Murray, Liam J and Coleman,
              Helen G and James, Jacqueline A and Salto-Tellez, Manuel and
              Hamilton, Peter W",
  journal  = "Sci. Rep.",
  volume   =  7,
  number   =  1,
  pages    =  16878,
  abstract = "QuPath is new bioimage analysis software designed to meet the
              growing need for a user-friendly, extensible, open-source solution
              for digital pathology and whole slide image analysis. In addition
              to offering a comprehensive panel of tumor identification and
              high-throughput biomarker evaluation tools, QuPath provides
              researchers with powerful batch-processing and scripting
              functionality, and an extensible platform with which to develop
              and share new algorithms to analyze complex tissue images.
              Furthermore, QuPath's flexible design makes it suitable for a wide
              range of additional image analysis applications across biomedical
              research.",
  month    =  dec,
  year     =  2017,
  language = "en"
}

@ARTICLE{de-Chaumont2012,
  title     = "Icy: an open bioimage informatics platform for extended
               reproducible research",
  author    = "de Chaumont, Fabrice and Dallongeville, Stéphane and Chenouard,
               Nicolas and Hervé, Nicolas and Pop, Sorin and Provoost, Thomas
               and Meas-Yedid, Vannary and Pankajakshan, Praveen and Lecomte,
               Timothée and Le Montagner, Yoann and Lagache, Thibault and
               Dufour, Alexandre and Olivo-Marin, Jean-Christophe",
  journal   = "Nat. Methods",
  publisher = "Springer Science and Business Media LLC",
  volume    =  9,
  number    =  7,
  pages     = "690--696",
  abstract  = "Current research in biology uses evermore complex computational
               and imaging tools. Here we describe Icy, a collaborative bioimage
               informatics platform that combines a community website for
               contributing and sharing tools and material, and software with a
               high-end visual programming framework for seamless development of
               sophisticated imaging workflows. Icy extends the reproducible
               research principles, by encouraging and facilitating the
               reusability, modularity, standardization and management of
               algorithms and protocols. Icy is free, open-source and available
               at http://icy.bioimageanalysis.org/.",
  month     =  jun,
  year      =  2012,
  language  = "en"
}

@ARTICLE{Berg2019,
  title     = "Ilastik: Interactive machine learning for (bio)image analysis",
  author    = "Berg, Stuart and Kutra, Dominik and Kroeger, Thorben and
               Straehle, Christoph N and Kausler, Bernhard X and Haubold,
               Carsten and Schiegg, Martin and Ales, Janez and Beier, Thorsten
               and Rudy, Markus and Eren, Kemal and Cervantes, Jaime I and Xu,
               Buote and Beuttenmueller, Fynn and Wolny, Adrian and Zhang, Chong
               and Koethe, Ullrich and Hamprecht, Fred A and Kreshuk, Anna",
  journal   = "Nat. Methods",
  publisher = "Springer Science and Business Media LLC",
  volume    =  16,
  number    =  12,
  pages     = "1226--1232",
  abstract  = "We present ilastik, an easy-to-use interactive tool that brings
               machine-learning-based (bio)image analysis to end users without
               substantial computational expertise. It contains pre-defined
               workflows for image segmentation, object classification, counting
               and tracking. Users adapt the workflows to the problem at hand by
               interactively providing sparse training annotations for a
               nonlinear classifier. ilastik can process data in up to five
               dimensions (3D, time and number of channels). Its computational
               back end runs operations on-demand wherever possible, allowing
               for interactive prediction on data larger than RAM. Once the
               classifiers are trained, ilastik workflows can be applied to new
               data from the command line without further user interaction. We
               describe all ilastik workflows in detail, including three case
               studies and a discussion on the expected performance.",
  month     =  dec,
  year      =  2019,
  language  = "en"
}

@ARTICLE{Arzt2022,
  title     = "{LABKIT}: Labeling and segmentation toolkit for big image data",
  author    = "Arzt, Matthias and Deschamps, Joran and Schmied, Christopher and
               Pietzsch, Tobias and Schmidt, Deborah and Tomancak, Pavel and
               Haase, Robert and Jug, Florian",
  journal   = "Front. Comput. Sci.",
  publisher = "Frontiers Media SA",
  volume    =  4,
  abstract  = "We present LABKIT, a user-friendly Fiji plugin for the
               segmentation of microscopy image data. It offers easy to use
               manual and automated image segmentation routines that can be
               rapidly applied to single- and multi-channel images as well as to
               timelapse movies in 2D or 3D. LABKIT is specifically designed to
               work efficiently on big image data and enables users of consumer
               laptops to conveniently work with multiple-terabyte images. This
               efficiency is achieved by using ImgLib2 and BigDataViewer as well
               as a memory efficient and fast implementation of the random
               forest based pixel classification algorithm as the foundation of
               our software. Optionally we harness the power of graphics
               processing units (GPU) to gain additional runtime performance.
               LABKIT is easy to install on virtually all laptops and
               workstations. Additionally, LABKIT is compatible with high
               performance computing (HPC) clusters for distributed processing
               of big image data. The ability to use pixel classifiers trained
               in LABKIT via the ImageJ macro language enables our users to
               integrate this functionality as a processing step in automated
               image processing workflows. Finally, LABKIT comes with rich
               online resources such as tutorials and examples that will help
               users to familiarize themselves with available features and how
               to best use LABKIT in a number of practical real-world use-cases.",
  month     =  feb,
  year      =  2022
}

@INPROCEEDINGS{Schmidt2018,
  title     = "Cell Detection with Star-Convex Polygons",
  author    = "Schmidt, Uwe and Weigert, Martin and Broaddus, Coleman and Myers,
               Gene",
  booktitle = "Medical Image Computing and Computer Assisted Intervention –
               MICCAI 2018",
  publisher = "Springer International Publishing",
  pages     = "265--273",
  abstract  = "Automatic detection and segmentation of cells and nuclei in
               microscopy images is important for many biological applications.
               Recent successful learning-based approaches include per-pixel
               cell segmentation with subsequent pixel grouping, or localization
               of bounding boxes with subsequent shape refinement. In situations
               of crowded cells, these can be prone to segmentation errors, such
               as falsely merging bordering cells or suppressing valid cell
               instances due to the poor approximation with bounding boxes. To
               overcome these issues, we propose to localize cell nuclei via
               star-convex polygons, which are a much better shape
               representation as compared to bounding boxes and thus do not need
               shape refinement. To that end, we train a convolutional neural
               network that predicts for every pixel a polygon for the cell
               instance at that position. We demonstrate the merits of our
               approach on two synthetic datasets and one challenging dataset of
               diverse fluorescence microscopy images.",
  year      =  2018
}

@ARTICLE{Goldsborough2024,
  title         = "{InstanSeg}: an embedding-based instance segmentation
                   algorithm optimized for accurate, efficient and portable cell
                   segmentation",
  author        = "Goldsborough, Thibaut and Philps, Ben and O'Callaghan, Alan
                   and Inglis, Fiona and Leplat, Leo and Filby, Andrew and
                   Bilen, Hakan and Bankhead, Peter",
  journal       = "arXiv [cs.CV]",
  abstract      = "Cell and nucleus segmentation are fundamental tasks for
                   quantitative bioimage analysis. Despite progress in recent
                   years, biologists and other domain experts still require
                   novel algorithms to handle increasingly large and complex
                   real-world datasets. These algorithms must not only achieve
                   state-of-the-art accuracy, but also be optimized for
                   efficiency, portability and user-friendliness. Here, we
                   introduce InstanSeg: a novel embedding-based instance
                   segmentation pipeline designed to identify cells and nuclei
                   in microscopy images. Using six public cell segmentation
                   datasets, we demonstrate that InstanSeg can significantly
                   improve accuracy when compared to the most widely used
                   alternative methods, while reducing the processing time by at
                   least 60\%. Furthermore, InstanSeg is designed to be fully
                   serializable as TorchScript and supports GPU acceleration on
                   a range of hardware. We provide an open-source implementation
                   of InstanSeg in Python, in addition to a user-friendly,
                   interactive QuPath extension for inference written in Java.
                   Our code and pre-trained models are available at
                   https://github.com/instanseg/instanseg .",
  month         =  aug,
  year          =  2024,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV"
}

@ARTICLE{Archit2025,
  title     = "Segment Anything for microscopy",
  author    = "Archit, Anwai and Freckmann, Luca and Nair, Sushmita and Khalid,
               Nabeel and Hilt, Paul and Rajashekar, Vikas and Freitag, Marei
               and Teuber, Carolin and Buckley, Genevieve and von Haaren,
               Sebastian and Gupta, Sagnik and Dengel, Andreas and Ahmed, Sheraz
               and Pape, Constantin",
  journal   = "Nat. Methods",
  publisher = "Springer Science and Business Media LLC",
  volume    =  22,
  number    =  3,
  pages     = "579--591",
  abstract  = "Accurate segmentation of objects in microscopy images remains a
               bottleneck for many researchers despite the number of tools
               developed for this purpose. Here, we present Segment Anything for
               Microscopy (μSAM), a tool for segmentation and tracking in
               multidimensional microscopy data. It is based on Segment
               Anything, a vision foundation model for image segmentation. We
               extend it by fine-tuning generalist models for light and electron
               microscopy that clearly improve segmentation quality for a wide
               range of imaging conditions. We also implement interactive and
               automatic segmentation in a napari plugin that can speed up
               diverse segmentation tasks and provides a unified solution for
               microscopy annotation across different microscopy modalities. Our
               work constitutes the application of vision foundation models in
               microscopy, laying the groundwork for solving image analysis
               tasks in this domain with a small set of powerful deep learning
               models.",
  month     =  mar,
  year      =  2025,
  language  = "en"
}

@ARTICLE{Pachitariu2022,
  title     = "Cellpose 2.0: how to train your own model",
  author    = "Pachitariu, Marius and Stringer, Carsen",
  journal   = "Nat. Methods",
  publisher = "Springer Science and Business Media LLC",
  volume    =  19,
  number    =  12,
  pages     = "1634--1641",
  abstract  = "Pretrained neural network models for biological segmentation can
               provide good out-of-the-box results for many image types.
               However, such models do not allow users to adapt the segmentation
               style to their specific needs and can perform suboptimally for
               test images that are very different from the training images.
               Here we introduce Cellpose 2.0, a new package that includes an
               ensemble of diverse pretrained models as well as a
               human-in-the-loop pipeline for rapid prototyping of new custom
               models. We show that models pretrained on the Cellpose dataset
               can be fine-tuned with only 500-1,000 user-annotated regions of
               interest (ROI) to perform nearly as well as models trained on
               entire datasets with up to 200,000 ROI. A human-in-the-loop
               approach further reduced the required user annotation to 100-200
               ROI, while maintaining high-quality segmentations. We provide
               software tools such as an annotation graphical user interface, a
               model zoo and a human-in-the-loop pipeline to facilitate the
               adoption of Cellpose 2.0.",
  month     =  dec,
  year      =  2022,
  language  = "en"
}

@ARTICLE{Zhang2023,
  title         = "Bio-Image Informatics Index {BIII}: A unique database of
                   image analysis tools and workflows for and by the bioimaging
                   community",
  author        = "Zhang, Chong and Gaignard, Alban and Kalas, Matus and Levet,
                   Florian and Delestro, Felipe and Lindblad, Joakim and
                   Sladoje, Natasa and Plantard, Laure and Latour, Alain and
                   Haase, Robert and Martins, Gabriel and Sampaio, Paula and
                   Scholz, Leandro and Taggers, Neubias and Tosi, Sébastien and
                   Miura, Kota and Colombelli, Julien and Paul-Gilloteaux,
                   Perrine",
  journal       = "arXiv [q-bio.QM]",
  abstract      = "Bio image analysis has recently become one keystone of
                   biological research but biologists tend to get lost in a
                   plethora of available software and the way to adjust
                   available tools to their own image analysis problem. We
                   present BIII, BioImage Informatic Index (www.biii.eu), the
                   result of the first large community effort to bridge the
                   communities of algorithm and software developers, bioimage
                   analysts and biologists, under the form of a web-based
                   knowledge database crowdsourced by these communities.
                   Software tools (> 1300), image databases for benchmarking
                   (>20) and training materials (>70) for bio image analysis are
                   referenced and curated following standards constructed by the
                   community and then reaching a broader audience. Software
                   tools are organized as full protocol of analysis (workflow),
                   specific brick (component) to construct a workflow, or
                   software platform or library (collection). They are described
                   using Edam Bio Imaging, which is iteratively defined using
                   this website. All entries are exposed following FAIR
                   principles and accessible for other usage.",
  month         =  dec,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "q-bio.QM"
}

@ARTICLE{Ouyang2022,
  title    = "{BioImage} Model Zoo: A Community-Driven Resource for Accessible
              Deep Learning in {BioImage} Analysis",
  author   = "Ouyang, Wei and Beuttenmueller, Fynn and Gómez-de-Mariscal,
              Estibaliz and Pape, Constantin and Burke, Tom and
              Garcia-López-de-Haro, Carlos and Russell, Craig and Moya-Sans,
              Lucía and de-la-Torre-Gutiérrez, Cristina and Schmidt, Deborah and
              Kutra, Dominik and Novikov, Maksim and Weigert, Martin and
              Schmidt, Uwe and Bankhead, Peter and Jacquemet, Guillaume and
              Sage, Daniel and Henriques, Ricardo and Muñoz-Barrutia, Arrate and
              Lundberg, Emma and Jug, Florian and Kreshuk, Anna",
  journal  = "bioRxiv",
  pages    = "2022.06.07.495102",
  abstract = "Deep learning-based approaches are revolutionizing imaging-driven
              scientific research. However, the accessibility and
              reproducibility of deep learning-based workflows for imaging
              scientists remain far from sufficient. Several tools have recently
              risen to the challenge of democratizing deep learning by providing
              user-friendly interfaces to analyze new data with pre-trained or
              fine-tuned models. Still, few of the existing pre-trained models
              are interoperable between these tools, critically restricting a
              model’s overall utility and the possibility of validating and
              reproducing scientific analyses. Here, we present the BioImage
              Model Zoo (): a community-driven, fully open resource where
              standardized pre-trained models can be shared, explored, tested,
              and downloaded for further adaptation or direct deployment in
              multiple end user-facing tools (e.g., ilastik, deepImageJ, QuPath,
              StarDist, ImJoy, ZeroCostDL4Mic, CSBDeep). To enable everyone to
              contribute and consume the Zoo resources, we provide a model
              standard to enable cross-compatibility, a rich list of example
              models and practical use-cases, developer tools, documentation,
              and the accompanying infrastructure for model upload, download and
              testing. Our contribution aims to lay the groundwork to make deep
              learning methods for microscopy imaging findable, accessible,
              interoperable, and reusable (FAIR) across software tools and
              platforms. \#\#\# Competing Interest Statement The authors have
              declared no competing interest.",
  month    =  jun,
  year     =  2022,
  language = "en"
}

@ARTICLE{Rueden2019,
  title    = "Scientific Community Image Forum: A discussion forum for
              scientific image software",
  author   = "Rueden, Curtis T and Ackerman, Jeanelle and Arena, Ellen T and
              Eglinger, Jan and Cimini, Beth A and Goodman, Allen and Carpenter,
              Anne E and Eliceiri, Kevin W",
  journal  = "PLoS Biol.",
  volume   =  17,
  number   =  6,
  pages    = "e3000340",
  abstract = "Forums and email lists play a major role in assisting scientists
              in using software. Previously, each open-source bioimaging
              software package had its own distinct forum or email list.
              Although each provided access to experts from various software
              teams, this fragmentation resulted in many scientists not knowing
              where to begin with their projects. Thus, the scientific imaging
              community lacked a central platform where solutions could be
              discussed in an open, software-independent manner. In response, we
              introduce the Scientific Community Image Forum, where users can
              pose software-related questions about digital image analysis,
              acquisition, and data management.",
  month    =  jun,
  year     =  2019,
  language = "en"
}

@ARTICLE{Gomez-de-Mariscal2021,
  title     = "{DeepImageJ}: A user-friendly environment to run deep learning
               models in {ImageJ}",
  author    = "Gómez-de-Mariscal, Estibaliz and García-López-de-Haro, Carlos and
               Ouyang, Wei and Donati, Laurène and Lundberg, Emma and Unser,
               Michael and Muñoz-Barrutia, Arrate and Sage, Daniel",
  journal   = "Nat. Methods",
  publisher = "Springer Science and Business Media LLC",
  volume    =  18,
  number    =  10,
  pages     = "1192--1195",
  abstract  = "DeepImageJ is a user-friendly solution that enables the generic
               use of pre-trained deep learning models for biomedical image
               analysis in ImageJ. The deepImageJ environment gives access to
               the largest bioimage repository of pre-trained deep learning
               models (BioImage Model Zoo). Hence, nonexperts can easily perform
               common image processing tasks in life-science research with deep
               learning-based tools including pixel and object classification,
               instance segmentation, denoising or virtual staining. DeepImageJ
               is compatible with existing state of the art solutions and it is
               equipped with utility tools for developers to include new models.
               Very recently, several training frameworks have adopted the
               deepImageJ format to deploy their work in one of the most used
               softwares in the field (ImageJ). Beyond its direct use, we expect
               deepImageJ to contribute to the broader dissemination and reuse
               of deep learning models in life sciences applications and
               bioimage informatics.",
  month     =  oct,
  year      =  2021,
  language  = "en"
}

@ARTICLE{Ouyang2019,
  title     = "{ImJoy}: an open-source computational platform for the deep
               learning era",
  author    = "Ouyang, Wei and Mueller, Florian and Hjelmare, Martin and
               Lundberg, Emma and Zimmer, Christophe",
  journal   = "Nat. Methods",
  publisher = "Springer Science and Business Media LLC",
  volume    =  16,
  number    =  12,
  pages     = "1199--1200",
  month     =  dec,
  year      =  2019,
  language  = "en"
}

@MISC{Shah,
  title    = "Bilayers",
  author   = "Shah, Rajavi and Gogoberidze, Nodar and Cimini, Beth",
  abstract = "A Container Specification and CI/CD built for whole-community
              support",
  url      = "https://github.com/bilayer-containers/bilayers"
}

@ARTICLE{Hidalgo-Cenalmor2024,
  title     = "{DL4MicEverywhere}: deep learning for microscopy made flexible,
               shareable and reproducible",
  author    = "Hidalgo-Cenalmor, Iván and Pylvänäinen, Joanna W and G Ferreira,
               Mariana and Russell, Craig T and Saguy, Alon and
               Arganda-Carreras, Ignacio and Shechtman, Yoav and {AI4Life
               Horizon Europe Program Consortium} and Jacquemet, Guillaume and
               Henriques, Ricardo and Gómez-de-Mariscal, Estibaliz",
  journal   = "Nat. Methods",
  publisher = "Springer Science and Business Media LLC",
  volume    =  21,
  number    =  6,
  pages     = "925--927",
  month     =  jun,
  year      =  2024,
  language  = "en"
}

@inproceedings{jupyter,
       booktitle = {Positioning and Power in Academic Publishing: Players, Agents and Agendas},
          editor = {Fernando Loizides and Birgit Scmidt},
           title = {Jupyter Notebooks - a publishing format for reproducible computational workflows},
          author = {Thomas Kluyver and Benjamin Ragan-Kelley and Fernando P{\'e}rez and Brian Granger and Matthias Bussonnier and Jonathan Frederic and Kyle Kelley and Jessica Hamrick and Jason Grout and Sylvain Corlay and Paul Ivanov and Dami{\'a}n Avila and Safia Abdalla and Carol Willing and  Jupyter development team},
       publisher = {IOS Press},
         address = {Netherlands},
            year = {2016},
           pages = {87--90},
             url = {https://eprints.soton.ac.uk/403913/},
        abstract = {It is increasingly necessary for researchers in all fields to write computer code, and in order to reproduce research results, it is important that this code is published. We present Jupyter notebooks, a document format for publishing code, results and explanations in a form that is both readable and executable. We discuss various tools and use cases for notebook documents.}
}

@ARTICLE{Kreshuk2019,
  title    = "Machine Learning: Advanced Image Segmentation Using ilastik",
  author   = "Kreshuk, Anna and Zhang, Chong",
  journal  = "Methods Mol. Biol.",
  volume   =  2040,
  pages    = "449--463",
  abstract = "Segmentation is one of the most ubiquitous problems in biological
              image analysis. Here we present a machine learning-based solution
              to it as implemented in the open source ilastik toolkit. We give a
              broad description of the underlying theory and demonstrate two
              workflows: Pixel Classification and Autocontext. We illustrate
              their use on a challenging problem in electron microscopy image
              segmentation. After following this walk-through, we expect the
              readers to be able to apply the necessary steps to their own data
              and segment their images by either workflow.",
  year     =  2019,
  keywords = "Machine learning; Random forest; Semantic segmentation; ilastik",
  language = "en"
}
