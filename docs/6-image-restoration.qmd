---
author: 
  - name: Min Guo
    orcid: 0000-0002-2093-8771
    affiliations:
      - name: Zhejiang University
        country: China
  - name: Hari Shroff
    orcid: 0000-0003-3613-8215
    affiliations:
      - name: HHMI Janelia Research Campus
        state: VA
        country: USA
        postal-code: 20147
subtitle: Microscopic Image Restoration with Artificial Intelligence
---
# Microscopic Image Restoration with Artificial Intelligence

Fluorescence microscopy is central to biological discovery, enabling the visualization of cellular and subcellular structures with exquisite detail. From observing dynamic intracellular processes to mapping entire tissues, microscopy is indispensable for understanding biological systems. However, the quality of microscopic images is often compromised due to intrinsic limitations such as noise, optical aberrations, diffraction, and limited signal. These factors hinder analysis and interpretation, particularly when studying fine biological structures or dynamic processes. [to give some specific examples of ‘analysis and interpretation’ tasks, e.g. segmentation/quantification/tracking etc.]

To overcome these challenges, image restoration techniques have been developed to enhance the quality of microscopic images by addressing limitations due to signal, noise, blur, aberrations, and spatial resolution. Traditionally, these techniques relied on mathematical algorithms and physical models of the imaging process. However, recent advances in artificial intelligence (AI), particularly deep learning, have transformed image restoration by enabling data-driven approaches that offer improved performance and flexibility.

In this chapter, we provide a practical overview of image restoration for applications in fluorescence microscopy. We begin by introducing the general concept of image restoration, then describe traditional and deep learning-based approaches. Next, we review key technologies and advances by categorizing the field in four major areas: denoising, deconvolution, deaberration, and resolution enhancement. Finally, we provide practical guidelines for implementing image restoration, including step-by-step workflows and test datasets for readers to practice applying these methods.

# General Concepts in Image Restoration

Image restoration is the process of improving the quality of degraded images by mitigating the effects of noise, blur, aberrations, and other artifacts. In microscopy, restoration is particularly important because optical systems often operate at physical limits, such as the diffraction limit of resolution or the signal budget available for live imaging. Restoration techniques aim to better estimate the underlying sample structure than the raw data.

## Image Restoration with Traditional Approaches

Start by explaining the image degradation model with the following formula and then guide the readers to the four kinds of image restoration in this chapter.

$$
i = e \otimes f ( \phi ) + n
$$ {#eq-image_restoration}

Traditional methods of image restoration rely on mathematical modeling of the imaging process and statistical analysis. These approaches address specific image degradation issues, such as noise, blur, or aberrations. Common techniques include:

1.	Denoising: Filtering-based methods like mean filtering, Gaussian filtering, median filtering, and non-local means are used to reduce noise while preserving image details.
2.	Deconvolution: Algorithms like Richardson-Lucy deconvolution use the point spread function (PSF) of the microscope to reverse the effects of optical blur.
3.	Deaberration: Wavefront correction (e.g., adaptive optics) mitigates aberrations caused by refractive index mismatches in the sample.[mention the concept of aberrations when explaining the above formula, and describe it in more detail here.]
4.	Resolution Enhancement: Optical super-resolution techniques, like structured illumination microscopy (SIM) and stimulated emission depletion (STED), bypass the diffraction limit.

While effective, traditional methods often require precise modeling of the imaging system, careful parameter tuning, and significant computational resources. Moreover, their performance can be limited in highly noisy or complex imaging conditions.

## Image Restoration with Deep Learning-Based Approaches

The advent of artificial intelligence (AI), particularly deep learning, has transformed image restoration in microscopy. Deep learning models, such as convolutional neural networks (CNNs), are capable of learning complex patterns and relationships directly from data without explicit modeling of the imaging system. These models offer several advantages:

* Data-Driven: Deep learning algorithms learn from paired datasets of degraded images and their high-quality counterparts, making them adaptable to diverse imaging conditions.
*	Generalization: Once trained, AI models can generalize to new datasets with similar imaging conditions or sample structure, enabling rapid restoration. [Mention the limitations of DL vs traditional methods: also in Section 5/caveats.]
*	Performance: Deep learning methods often outperform traditional approaches in denoising, deconvolution, and resolution enhancement, especially for low signal-to-noise ratio (SNR) data.

Recent advances, such as content-aware restoration (CARE), residual channel attention networks (RCANs), and deep Fourier-based models, have demonstrated remarkable success in improving image quality while reducing phototoxicity and photobleaching during acquisition.

# Deep Learning-Based Techniques for Image Restoration 

We categorize image restoration into four main areas: denoising, deconvolution, deaberration, and resolution enhancement. Each category addresses a specific type of image degradation, contributing to improved visualization and analysis.

## Denoising

* Noise2Noise
* Noise2Void
* CARE
* RCAN
* And more

## Deconvolution

* Supervised Learning: Neural networks trained on paired low-resolution and high-resolution images can predict deblurred outputs, eg, 3D RCAN.
* Physics-Informed Models: Incorporating PSF models into deep learning frameworks improves interpretability and performance, eg, RL-net.

## Deaberration

* Wavefront Prediction: Neural networks trained to explicitly sense aberrated wavefront.
* Aberration removal on images: Neural networks trained on paired aberrated and corrected images to predict aberration corrections without explicit wavefront sensing, e.g, DeAbe model, HD2Net.

## Resolution Enhancement

* Cross-Modality Super-Resolution: Neural networks trained on paired low-resolution and high-resolution datasets (e.g., confocal to STED with 3D-RCAN) can improve spatial resolution while reducing phototoxicity.
* Fourier-Based Approaches: Frequency domain models enhance high-frequency details, enabling long-term super-resolution imaging, e.g, DFCAN for SIM.
* Expansion Microscopy-Inspired Models: Networks trained on expansion microscopy data predict super-resolution images from diffraction-limited inputs. [Note: to mention the importance of precise registration.]

# Practical Guidelines for Image Registration

## Step-by-step Workflow

1. Dataset preparation
  * Acquire paired datasets of degraded and high-quality images for supervised training.
  * For unsupervised methods, collect degraded images with varying conditions.

2. Model Training
  * Use open-source frameworks like TensorFlow or PyTorch.
  * Choose or design networks (e.g., CARE, Noise2Void), or even start with pre-trained models for faster deployment.

3. Validation
  * Validate restoration quality using metrics like SSIM and PSNR.
  * Perform biological validation to ensure restored images are artifact-free.

4. 3D-RCAN as an example to get feet wet
  * See the PDF (complied from GitHub Markdown) as an appendix

<span style="color:red">Figures to illustrate each section</span>.

# Failure Modes and Outlook for the Future

  * Caveats and issues: guidance and comments.
  * Newer methods and looking forward: transformers and others.


<!--# Extending Your Hardware With AI-->
<!--Your first header will be the chapter's upper-level table of contents title.-->
<!--If you'd like to have a subtitle, include it in the Quarto header above -->

<!---
Under your first header, include a brief introduction to your chapter.

Starting prompt for this chapter: This image restoration focused chapter motivates how AI can improve the image quality beyond hardware limitations. This chapter should include image restoration (denoising) and sensor-less AO (deep-learning-based AO); other topics can be included at the author’s discretion.

Notes from the authors' meeting: This chapter can start with a broader overview of the topic, which will reference existing reviews on the topic. Then the chapter will focus on a denoising tutorial, which will include discussions of potential pitfalls and best practices.

## Include section headers as appropriate

Use markdown heading level two for section headers. You can use standard markdown formatting, for example _emphasize the end of this sentence_.

This is a new paragraph with more text. Your paragraphs can cross reference other items, such as @fig-simple. Use `fig` to reference figures, and `eq` to reference equations, such as @eq-stddev.

###  Sub-subsection headers are also available

To make your sections cross reference-able throughout the book, include a section reference, as shown in the header for @sec-equation.

## Bibliography and Citations

To cite a research article, add it to references.bib and then refer to the citation key. For example, reference @stringer2021 refers to CellPose and reference @von_chamier2021 refers to ZeroCostDL4Mic.

## Adding to the Glossary

We are using the extension [Quarto-glossary](https://debruine.github.io/quarto-glossary/#styles) to create a glossary for this book. To add a definition, edit the glossary.yml file. To reference the glossary, enclose the word as in these examples: LLMs suffer from {{< glossary hallucinations >}}. It is important to understand the underlying {{< glossary "training data" >}} to interpret your results. Clicking on the word will reveal its definition. The complete glossary for the book will be listed in the [Glossary](glossary.qmd).

## Code and Equations {#sec-equation}

This is an example of including a python snippet that generates a figure

```{python}
#| label: fig-simple
#| fig-cap: "Simple Plot"
import matplotlib.pyplot as plt
plt.plot([1,23,2,4])
plt.show()
```


In some cases, you may want to include a code-block that is not executed when the book is compiled. Use the `eval: false` option for this.

```{python}
#| eval: false
import matplotlib.pyplot as plt
plt.plot([1,23,2,4])
plt.show()
```


Figures can also be generated that do not show the code by using the option for `code-fold: true`.

```{python}
#| code-fold: true
#| label: fig-polar
#| fig-cap: "A spiral on a polar axis"
#| fig-alt: "A line plot on a polar axis. The line spirals out from a value of zero to a value of 2."

import numpy as np
import matplotlib.pyplot as plt

r = np.arange(0, 2, 0.01)
theta = 2 * np.pi * r
fig, ax = plt.subplots(
  subplot_kw = {'projection': 'polar'} 
)
ax.plot(theta, r)
ax.set_rticks([0.5, 1, 1.5, 2])
ax.grid(True)
plt.show()
```

Here is an example equation.

$$
s = \sqrt{\frac{1}{N-1} \sum_{i=1}^N (x_i - \overline{x})^2}
$$ {#eq-stddev}

### Embedding Figures

You can also embed figures from other notebooks in the repo as shown in the following embed example.


{{< embed ../notebooks/test.ipynb#fig-test-fig echo-true >}}

When embedding notebooks, please store the .ipynb file in the notebook directory. Include the chapter in the name of your file. For example, `chapter4_example_u-net.ipynb`. This is how we will handle chapter- or example-specific environments. We will host notebooks on Google Colab so that any required packages for the code--but not for rendering the book at large--will be installed there. That way, we will not need to handle a global environment across the book.

## Quarto has additional features.

You can learn more about markdown options and additional Quarto features in the [Quarto documentation](https://quarto.org/docs/authoring/markdown-basics.html).  One example that you might find interesting is the option to include callouts in your text. These callouts can be used to highlight potential pitfalls or provide additional optional exercises that the reader might find helpful. Below are examples of the types of callouts available in Quarto.

::: {.callout-note}
Note that there are five types of callouts, including:
`note`, `tip`, `warning`, `caution`, and `important`. They can default to open (like this example) or collapsed (example below).
:::

::: {.callout-tip collapse="true"}
These could be good for extra material or exercises.
:::

::: {.callout-caution}
There are caveats when applying these tools. Expand the code below to learn more.

```{python}
#| code-fold: true
r = np.arange(0, 2, 0.01)
theta = 2 * np.pi * r
```
:::

::: {.callout-warning}
Be careful to avoid hallucinations.
:::

::: {.callout-important}
This is key information.
:::-->